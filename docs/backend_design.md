# åç«¯è¯¦ç»†è®¾è®¡æ–‡æ¡£

**é¡¹ç›®åç§°**: ytzc-ai-proxy (AIç½‘å…³ç³»ç»Ÿ)  
**æŠ€æœ¯æ ˆ**: Python 3.11 + FastAPI  
**æ–‡æ¡£ç‰ˆæœ¬**: 1.0  
**æœ€åæ›´æ–°**: 2026-02-24

---

## 1. ç³»ç»Ÿæ¶æ„æ¦‚è¿°

### 1.1 æ•´ä½“æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        å®¢æˆ·ç«¯å±‚                                  â”‚
â”‚  - ChatBox AI (é…ç½®proxy_key)                                   â”‚
â”‚  - frontend WebChatæµ‹è¯•é¡µ                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      FastAPIåç«¯ (Port 8000)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚   â”‚  /proxy/ai/v1/*  â”‚        â”‚  /admin/ai/v1/*  â”‚             â”‚
â”‚   â”‚  è™šæ‹ŸAIä»£ç†API    â”‚        â”‚  åå°ç®¡ç†API      â”‚             â”‚
â”‚   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤             â”‚
â”‚   â”‚  â€¢ chat          â”‚        â”‚  â€¢ config        â”‚             â”‚
â”‚   â”‚  â€¢ models        â”‚        â”‚  â€¢ models        â”‚             â”‚
â”‚   â”‚  â€¢ embeddings    â”‚        â”‚  â€¢ skills        â”‚             â”‚
â”‚   â”‚                  â”‚        â”‚  â€¢ knowledge     â”‚             â”‚
â”‚   â”‚  è®¤è¯: proxy_key â”‚        â”‚  â€¢ media         â”‚             â”‚
â”‚   â”‚  æµå¼: SSE       â”‚        â”‚  â€¢ rss           â”‚             â”‚
â”‚   â”‚                  â”‚        â”‚  â€¢ logs          â”‚             â”‚
â”‚   â”‚                  â”‚        â”‚  â€¢ raw-data      â”‚             â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚           â”‚                            â”‚                       â”‚
â”‚           â–¼                            â–¼                       â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚   â”‚   æ¨¡å‹è·¯ç”±å¼•æ“    â”‚        â”‚   Skillç®¡ç†å™¨    â”‚             â”‚
â”‚   â”‚                  â”‚        â”‚                  â”‚             â”‚
â”‚   â”‚  â€¢ å…³é”®è¯åŒ¹é…    â”‚        â”‚  â€¢ åŠ¨æ€åŠ è½½      â”‚             â”‚
â”‚   â”‚  â€¢ æ„å›¾è¯†åˆ«      â”‚        â”‚  â€¢ ç‰ˆæœ¬ç®¡ç†      â”‚             â”‚
â”‚   â”‚  â€¢ å¼ºåˆ¶æ¨¡å¼      â”‚        â”‚  â€¢ çƒ­é‡è½½        â”‚             â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                     â–¼                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   å¤–éƒ¨API     â”‚    â”‚    æ•°æ®å­˜å‚¨å±‚     â”‚   â”‚   æœåŠ¡ç»„ä»¶    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ SiliconFlow  â”‚    â”‚ MongoDB          â”‚   â”‚ Redis        â”‚
â”‚ OpenAI       â”‚    â”‚  - å¯¹è¯å†å²      â”‚   â”‚  - ä¼šè¯ç¼“å­˜  â”‚
â”‚ Ollama       â”‚    â”‚  - é…ç½®æ•°æ®      â”‚   â”‚  - é…ç½®ç¼“å­˜  â”‚
â”‚              â”‚    â”‚  - æ“ä½œæ—¥å¿—      â”‚   â”‚  - ä»»åŠ¡é˜Ÿåˆ—  â”‚
â”‚              â”‚    â”‚                  â”‚   â”‚              â”‚
â”‚              â”‚    â”‚ Qdrant           â”‚   â”‚ Whisper      â”‚
â”‚              â”‚    â”‚  - å‘é‡åº“        â”‚   â”‚  - éŸ³é¢‘è½¬å½•  â”‚
â”‚              â”‚    â”‚  - çŸ¥è¯†æ£€ç´¢      â”‚   â”‚  - è§†é¢‘è½¬å½•  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 æ ¸å¿ƒç»„ä»¶èŒè´£

| ç»„ä»¶ | èŒè´£ | æŠ€æœ¯å®ç° |
|------|------|----------|
| **API Router** | è·¯ç”±åˆ†å‘ã€è¯·æ±‚éªŒè¯ | FastAPI APIRouter |
| **Auth Middleware** | proxy_keyéªŒè¯ | è‡ªå®šä¹‰ä¸­é—´ä»¶ |
| **Model Router** | æ™ºèƒ½è·¯ç”±å†³ç­– | Skillé©±åŠ¨ |
| **Skill Manager** | SkillåŠ è½½ã€æ‰§è¡Œã€é‡è½½ | åŠ¨æ€å¯¼å…¥ + ç¼“å­˜ |
| **Config Manager** | é…ç½®è¯»å–ã€çƒ­é‡è½½ | YAML + Watchdog |
| **Conversation Manager** | å¯¹è¯CRUDã€æŒä¹…åŒ– | MongoDB |
| **Knowledge Manager** | çŸ¥è¯†æå–ã€å‘é‡å­˜å‚¨ | Qdrant + Embedding |
| **Media Processor** | éŸ³è§†é¢‘è½¬å½• | Whisper + Redisé˜Ÿåˆ— |
| **RSS Fetcher** | RSSæŠ“å–ã€å†…å®¹æå– | Feedparser + Readability |
| **Logger** | æ—¥å¿—è®°å½•ã€æŸ¥è¯¢ | MongoDB + æ–‡ä»¶ |

---

## 2. å­˜å‚¨å±‚æŠ½è±¡æ¶æ„ï¼ˆå¯æ›¿æ¢è®¾è®¡ï¼‰

### 2.1 è®¾è®¡ç›®æ ‡

**é—®é¢˜**: MongoDB/Qdrant/Redis æœªæ¥å¯èƒ½è¢«åŒç±»å‹äº§å“æ›¿æ¢

**è§£å†³æ–¹æ¡ˆ**: ä½¿ç”¨ Repository + Adapter + Factory æ¨¡å¼è¿›è¡ŒæŠ½è±¡å°è£…

**ä¼˜åŠ¿**:
- ä¸šåŠ¡ä»£ç ä¸å­˜å‚¨å®ç°è§£è€¦
- é€šè¿‡é…ç½®æ–‡ä»¶åˆ‡æ¢å­˜å‚¨ç±»å‹
- æ–°å¢å­˜å‚¨æ”¯æŒåªéœ€å®ç°æ¥å£

### 2.2 æŠ½è±¡æ¥å£å±‚

#### 2.2.1 æ–‡æ¡£å­˜å‚¨æ¥å£ï¼ˆæ›¿ä»£MongoDBï¼‰

```python
# core/repositories/interfaces.py

from abc import ABC, abstractmethod
from typing import List, Tuple, Optional, Dict, Any
from enum import Enum

class StorageType(str, Enum):
    MONGODB = "mongodb"
    POSTGRESQL = "postgresql"
    MYSQL = "mysql"
    DYNAMODB = "dynamodb"

class IDocumentRepository(ABC):
    """æ–‡æ¡£å­˜å‚¨æŠ½è±¡æ¥å£"""
    
    @abstractmethod
    async def connect(self) -> None:
        """å»ºç«‹è¿æ¥"""
        pass
    
    @abstractmethod
    async def disconnect(self) -> None:
        """å…³é—­è¿æ¥"""
        pass
    
    @abstractmethod
    async def insert_one(self, collection: str, document: Dict[str, Any]) -> str:
        """æ’å…¥å•æ¡æ–‡æ¡£ï¼Œè¿”å›ID"""
        pass
    
    @abstractmethod
    async def find_one(self, collection: str, query: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """æŸ¥è¯¢å•æ¡"""
        pass
    
    @abstractmethod
    async def find_many(
        self, 
        collection: str, 
        query: Dict[str, Any],
        sort: Optional[List[tuple]] = None,
        skip: int = 0,
        limit: int = 20
    ) -> Tuple[List[Dict[str, Any]], int]:
        """æŸ¥è¯¢å¤šæ¡ï¼Œè¿”å›æ•°æ®å’Œæ€»æ•°"""
        pass
    
    @abstractmethod
    async def update_one(
        self, 
        collection: str, 
        query: Dict[str, Any], 
        update: Dict[str, Any]
    ) -> bool:
        """æ›´æ–°å•æ¡"""
        pass
    
    @abstractmethod
    async def delete_one(self, collection: str, query: Dict[str, Any]) -> bool:
        """åˆ é™¤å•æ¡"""
        pass
```

#### 2.2.2 å‘é‡å­˜å‚¨æ¥å£ï¼ˆæ›¿ä»£Qdrantï¼‰

```python
class VectorDBType(str, Enum):
    QDRANT = "qdrant"
    MILVUS = "milvus"
    PINECONE = "pinecone"
    WEAVIATE = "weaviate"

class IVectorRepository(ABC):
    """å‘é‡å­˜å‚¨æŠ½è±¡æ¥å£"""
    
    @abstractmethod
    async def connect(self) -> None:
        pass
    
    @abstractmethod
    async def disconnect(self) -> None:
        pass
    
    @abstractmethod
    async def create_collection(
        self, 
        name: str, 
        dimension: int, 
        distance: str = "cosine"
    ) -> None:
        """åˆ›å»ºé›†åˆ"""
        pass
    
    @abstractmethod
    async def upsert(
        self, 
        collection: str, 
        vectors: List[Dict[str, Any]]
    ) -> None:
        """
        æ’å…¥/æ›´æ–°å‘é‡
        vectors: [{"id": "uuid", "vector": [0.1, ...], "payload": {...}}]
        """
        pass
    
    @abstractmethod
    async def search(
        self,
        collection: str,
        query_vector: List[float],
        top_k: int = 10,
        threshold: float = 0.7,
        filters: Optional[Dict[str, Any]] = None
    ) -> List[Dict[str, Any]]:
        """å‘é‡æœç´¢"""
        pass
    
    @abstractmethod
    async def delete(self, collection: str, ids: List[str]) -> None:
        """åˆ é™¤å‘é‡"""
        pass
```

#### 2.2.3 ç¼“å­˜æ¥å£ï¼ˆæ›¿ä»£Redisï¼‰

```python
class CacheType(str, Enum):
    REDIS = "redis"
    RABBITMQ = "rabbitmq"
    KAFKA = "kafka"

class ICacheRepository(ABC):
    """ç¼“å­˜æŠ½è±¡æ¥å£"""
    
    @abstractmethod
    async def connect(self) -> None:
        pass
    
    @abstractmethod
    async def disconnect(self) -> None:
        pass
    
    @abstractmethod
    async def get(self, key: str) -> Optional[str]:
        """è·å–ç¼“å­˜"""
        pass
    
    @abstractmethod
    async def set(self, key: str, value: str, expire: Optional[int] = None) -> None:
        """è®¾ç½®ç¼“å­˜"""
        pass
    
    @abstractmethod
    async def delete(self, key: str) -> None:
        """åˆ é™¤ç¼“å­˜"""
        pass
    
    @abstractmethod
    async def lpush(self, queue: str, value: str) -> None:
        """é˜Ÿåˆ—-å·¦ä¾§æ¨å…¥"""
        pass
    
    @abstractmethod
    async def rpop(self, queue: str, timeout: int = 0) -> Optional[str]:
        """é˜Ÿåˆ—-å³ä¾§å¼¹å‡ºï¼ˆé˜»å¡ï¼‰"""
        pass
```

### 2.3 å·¥å‚æ¨¡å¼å®ç°

```python
# core/repositories/factory.py

class RepositoryFactory:
    """å­˜å‚¨ä»“åº“å·¥å‚ - æ ¹æ®é…ç½®åˆ›å»ºå¯¹åº”å®ç°"""
    
    _document_impls = {}
    _vector_impls = {}
    _cache_impls = {}
    
    @classmethod
    def register_document(cls, storage_type: StorageType, impl_class: type):
        """æ³¨å†Œæ–‡æ¡£å­˜å‚¨å®ç°"""
        cls._document_impls[storage_type] = impl_class
    
    @classmethod
    def create_document_repository(cls, config: Dict[str, Any]) -> IDocumentRepository:
        """åˆ›å»ºæ–‡æ¡£å­˜å‚¨ä»“åº“"""
        storage_type = StorageType(config["type"])
        impl_class = cls._document_impls.get(storage_type)
        
        if not impl_class:
            raise ValueError(f"ä¸æ”¯æŒçš„å­˜å‚¨ç±»å‹: {storage_type}")
        
        return impl_class(**{k: v for k, v in config.items() if k != "type"})
    
    @classmethod
    def create_vector_repository(cls, config: Dict[str, Any]) -> IVectorRepository:
        """åˆ›å»ºå‘é‡å­˜å‚¨ä»“åº“"""
        vector_type = VectorDBType(config["type"])
        impl_class = cls._vector_impls.get(vector_type)
        
        if not impl_class:
            raise ValueError(f"ä¸æ”¯æŒçš„å‘é‡æ•°æ®åº“: {vector_type}")
        
        return impl_class(**{k: v for k, v in config.items() if k != "type"})
    
    @classmethod
    def create_cache_repository(cls, config: Dict[str, Any]) -> ICacheRepository:
        """åˆ›å»ºç¼“å­˜ä»“åº“"""
        cache_type = CacheType(config["type"])
        impl_class = cls._cache_impls.get(cache_type)
        
        if not impl_class:
            raise ValueError(f"ä¸æ”¯æŒçš„ç¼“å­˜ç±»å‹: {cache_type}")
        
        return impl_class(**{k: v for k, v in config.items() if k != "type"})

# æ³¨å†Œé»˜è®¤å®ç°
from .mongodb_adapter import MongoDBAdapter
from .qdrant_adapter import QdrantAdapter
from .redis_adapter import RedisAdapter

RepositoryFactory.register_document(StorageType.MONGODB, MongoDBAdapter)
RepositoryFactory.register_vector(VectorDBType.QDRANT, QdrantAdapter)
RepositoryFactory.register_cache(CacheType.REDIS, RedisAdapter)
```

### 2.4 é…ç½®é©±åŠ¨çš„å­˜å‚¨åˆ‡æ¢

```yaml
# config.yml ä¸­çš„å­˜å‚¨é…ç½®

storage:
  document:
    type: mongodb           # å¯é€‰: postgresql, mysql, dynamodb
    host: "mongo"
    port: 27017
    database: "ai_gateway"
    username: "admin"
    password: "password"
    
  vector:
    type: qdrant            # å¯é€‰: milvus, pinecone, weaviate
    host: "qdrant"
    port: 6333
    collection: "knowledge_base"
    
  cache:
    type: redis             # å¯é€‰: rabbitmq, kafka
    host: "redis"
    port: 6379
    db: 0
```

```python
# åˆå§‹åŒ–ä»£ç ç¤ºä¾‹

from core.repositories.factory import RepositoryFactory
from core.config import config_manager

# è¯»å–é…ç½®å¹¶åˆ›å»ºä»“åº“
doc_repo = RepositoryFactory.create_document_repository(
    config_manager.get("storage.document")
)
vector_repo = RepositoryFactory.create_vector_repository(
    config_manager.get("storage.vector")
)
cache_repo = RepositoryFactory.create_cache_repository(
    config_manager.get("storage.cache")
)

# è¿æ¥
await doc_repo.connect()
await vector_repo.connect()
await cache_repo.connect()
```

### 2.5 çŸ¥è¯†æå–æŠ½è±¡ï¼ˆé¢„ç•™OpenClawæ‰©å±•ï¼‰

```python
# core/extraction/interfaces.py

from abc import ABC, abstractmethod
from dataclasses import dataclass
from typing import List, Dict, Any, Optional
from enum import Enum

class ExtractorType(str, Enum):
    SKILL = "skill"           # å½“å‰å®ç°
    OPENCLAW = "openclaw"     # æœªæ¥æ‰©å±•
    HYBRID = "hybrid"         # æ··åˆæ¨¡å¼

@dataclass
class KnowledgeChunk:
    """çŸ¥è¯†ç‰‡æ®µ"""
    id: str
    content: str
    source: str
    confidence: float
    entities: List[Dict]
    relationships: List[Dict]      # é¢„ç•™ï¼šçŸ¥è¯†å›¾è°±å…³ç³»
    created_at: str
    metadata: Dict[str, Any]

@dataclass
class ExtractionResult:
    """æå–ç»“æœ"""
    chunks: List[KnowledgeChunk]
    total_chunks: int
    extracted_at: str
    extractor_type: ExtractorType
    processing_time_ms: int
    # é¢„ç•™OpenClawå­—æ®µ
    knowledge_graph_updated: bool = False
    conflicts_detected: Optional[List[Dict]] = None

class IKnowledgeExtractor(ABC):
    """çŸ¥è¯†æå–å™¨æŠ½è±¡æ¥å£"""
    
    @abstractmethod
    async def initialize(self) -> None:
        """åˆå§‹åŒ–"""
        pass
    
    @abstractmethod
    async def extract(
        self, 
        text: str, 
        context: Dict[str, Any]
    ) -> ExtractionResult:
        """ä»æ–‡æœ¬ä¸­æå–çŸ¥è¯†"""
        pass
    
    @abstractmethod
    async def classify_topic(
        self,
        text: str,
        topics: List[str]
    ) -> Optional[str]:
        """ä¸»é¢˜åˆ†ç±»"""
        pass

# å½“å‰Skillå®ç°
class SkillKnowledgeExtractor(IKnowledgeExtractor):
    """åŸºäºSkillçš„çŸ¥è¯†æå–å™¨"""
    
    def __init__(self, skill_manager: SkillManager):
        self.skill_manager = skill_manager
    
    async def initialize(self) -> None:
        pass
    
    async def extract(self, text: str, context: Dict[str, Any]) -> ExtractionResult:
        # è°ƒç”¨Skillæ‰§è¡ŒçŸ¥è¯†æå–
        result = await self.skill_manager.execute(
            "knowledge", "ç®€å•æå–",
            text=text, **context
        )
        
        return ExtractionResult(
            chunks=[KnowledgeChunk(**chunk) for chunk in result.get("chunks", [])],
            total_chunks=len(result.get("chunks", [])),
            extracted_at=datetime.now().isoformat(),
            extractor_type=ExtractorType.SKILL,
            processing_time_ms=result.get("duration_ms", 0)
        )
    
    async def classify_topic(self, text: str, topics: List[str]) -> Optional[str]:
        result = await self.skill_manager.execute(
            "knowledge", "ä¸»é¢˜åˆ†ç±»",
            text=text, topics=topics
        )
        return result.get("topic")

# å·¥å‚
class KnowledgeExtractorFactory:
    """çŸ¥è¯†æå–å™¨å·¥å‚"""
    
    _extractors = {
        ExtractorType.SKILL: SkillKnowledgeExtractor,
        # ExtractorType.OPENCLAW: OpenClawExtractor,  # æœªæ¥æ‰©å±•
    }
    
    @classmethod
    def create(cls, extractor_type: ExtractorType, **kwargs) -> IKnowledgeExtractor:
        impl_class = cls._extractors.get(extractor_type)
        if not impl_class:
            raise ValueError(f"æœªçŸ¥çš„æå–å™¨ç±»å‹: {extractor_type}")
        return impl_class(**kwargs)
    
    @classmethod
    def register(cls, extractor_type: ExtractorType, impl_class: type):
        """æ³¨å†Œæ–°çš„æå–å™¨ï¼ˆæ‰©å±•ç‚¹ï¼‰"""
        cls._extractors[extractor_type] = impl_class
```

---

### 2.6 å­˜å‚¨å±‚å®ç°çŠ¶æ€

**çŠ¶æ€**: âœ… **å·²å®ç°** (2026-02-14)

å­˜å‚¨å±‚æŠ½è±¡æ¶æ„å·²æŒ‰ç…§ç¬¬2.1-2.5èŠ‚çš„è®¾è®¡å®Œæ•´å®ç°ï¼Œä»£ç ä½äº `backend/core/repositories/` ç›®å½•ã€‚

**å®ç°çš„æ–‡ä»¶ç»“æ„**:
```
backend/core/repositories/
â”œâ”€â”€ __init__.py          # æ¨¡å—å¯¼å‡ºå’Œé€‚é…å™¨è‡ªåŠ¨æ³¨å†Œ
â”œâ”€â”€ interfaces.py        # æŠ½è±¡æ¥å£å®šä¹‰ï¼ˆIDocumentRepository, IVectorRepository, ICacheRepositoryï¼‰
â”œâ”€â”€ factory.py           # RepositoryFactory å·¥å‚ç±»
â”œâ”€â”€ mongodb_adapter.py   # MongoDBé€‚é…å™¨å®ç°
â”œâ”€â”€ qdrant_adapter.py    # Qdrantå‘é‡å­˜å‚¨é€‚é…å™¨å®ç°
â””â”€â”€ redis_adapter.py     # Redisç¼“å­˜é€‚é…å™¨å®ç°
```

**å®ç°çš„åŠŸèƒ½**:
1. âœ… å®Œæ•´çš„æŠ½è±¡æ¥å£å®šä¹‰ï¼ˆinterfaces.pyï¼‰
   - StorageType, VectorDBType, CacheType æšä¸¾
   - IDocumentRepository: 6ä¸ªæŠ½è±¡æ–¹æ³•
   - IVectorRepository: 6ä¸ªæŠ½è±¡æ–¹æ³•
   - ICacheRepository: 7ä¸ªæŠ½è±¡æ–¹æ³•

2. âœ… å·¥å‚æ¨¡å¼å®ç°ï¼ˆfactory.pyï¼‰
   - RepositoryFactory ç±»
   - è‡ªåŠ¨æ³¨å†Œæœºåˆ¶
   - é…ç½®é©±åŠ¨çš„ä»“åº“åˆ›å»º

3. âœ… å…·ä½“é€‚é…å™¨å®ç°
   - MongoDBAdapter: ä½¿ç”¨ Motor å®ç°å¼‚æ­¥ MongoDB æ“ä½œ
   - QdrantAdapter: ä½¿ç”¨ Qdrant å®¢æˆ·ç«¯å®ç°å‘é‡å­˜å‚¨
   - RedisAdapter: ä½¿ç”¨ Redis-py å®ç°ç¼“å­˜å’Œé˜Ÿåˆ—

4. âœ… è‡ªåŠ¨æ³¨å†Œ
   - åœ¨ `__init__.py` ä¸­è‡ªåŠ¨æ³¨å†Œæ‰€æœ‰é»˜è®¤é€‚é…å™¨
   - æ”¯æŒé€šè¿‡é…ç½®åˆ‡æ¢å­˜å‚¨åç«¯

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from core.repositories import RepositoryFactory

# åˆ›å»ºæ–‡æ¡£å­˜å‚¨ä»“åº“
doc_repo = RepositoryFactory.create_document_repository({
    "type": "mongodb",
    "host": "localhost",
    "port": 27017,
    "database": "ai_gateway"
})

# è¿æ¥å¹¶ä½¿ç”¨
await doc_repo.connect()
doc_id = await doc_repo.insert_one("users", {"name": "Alice"})
```

---

## 3. ç›®å½•ç»“æ„

```
backend/
â”œâ”€â”€ main.py                      # FastAPIåº”ç”¨å…¥å£
â”œâ”€â”€ requirements.txt             # ä¾èµ–åˆ—è¡¨
â”œâ”€â”€ pyproject.toml              # é¡¹ç›®é…ç½®ï¼ˆå¯é€‰ï¼‰
â”‚
â”œâ”€â”€ api/                        # APIè·¯ç”±å±‚
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ dependencies.py         # ä¾èµ–æ³¨å…¥ï¼ˆæ•°æ®åº“è¿æ¥ç­‰ï¼‰
â”‚   â”œâ”€â”€ proxy/                  # è™šæ‹ŸAIä»£ç†API
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ v1/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ chat.py         # POST /chat/completions
â”‚   â”‚       â”œâ”€â”€ models.py       # GET /models
â”‚   â”‚       â””â”€â”€ embeddings.py   # POST /embeddings
â”‚   â”‚
â”‚   â””â”€â”€ admin/                  # åå°ç®¡ç†API
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ v1/
â”‚           â”œâ”€â”€ __init__.py
â”‚           â”œâ”€â”€ dashboard.py    # çœ‹æ¿ç»Ÿè®¡/å¥åº·æ£€æŸ¥
â”‚           â”œâ”€â”€ config.py       # é…ç½®ç®¡ç†
â”‚           â”œâ”€â”€ models.py       # è™šæ‹Ÿæ¨¡å‹CRUD
â”‚           â”œâ”€â”€ skills.py       # Skillç®¡ç†
â”‚           â”œâ”€â”€ conversations.py # å¯¹è¯å†å²
â”‚           â”œâ”€â”€ knowledge.py    # çŸ¥è¯†åº“ç®¡ç†
â”‚           â”œâ”€â”€ media.py        # åª’ä½“å¤„ç†
â”‚           â”œâ”€â”€ rss.py          # RSSè®¢é˜…
â”‚           â”œâ”€â”€ logs.py         # æ—¥å¿—æŸ¥è¯¢
â”‚           â””â”€â”€ raw_data.py     # åŸå§‹æ•°æ®
â”‚
â”œâ”€â”€ core/                       # æ ¸å¿ƒä¸šåŠ¡é€»è¾‘
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py              # é…ç½®ç®¡ç†å™¨
â”‚   â”œâ”€â”€ security.py            # å®‰å…¨å·¥å…·ï¼ˆproxy_keyéªŒè¯ï¼‰
â”‚   â”‚
â”‚   â”œâ”€â”€ repositories/          # å­˜å‚¨å±‚æŠ½è±¡ï¼ˆæ–°å¢ï¼‰
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ interfaces.py      # æŠ½è±¡æ¥å£å®šä¹‰
â”‚   â”‚   â”œâ”€â”€ factory.py         # ä»“åº“å·¥å‚
â”‚   â”‚   â”œâ”€â”€ mongodb_adapter.py # MongoDBé€‚é…å™¨
â”‚   â”‚   â”œâ”€â”€ qdrant_adapter.py  # Qdranté€‚é…å™¨
â”‚   â”‚   â”œâ”€â”€ redis_adapter.py   # Redisé€‚é…å™¨
â”‚   â”‚   â””â”€â”€ postgresql_adapter.py  # PostgreSQLé€‚é…å™¨ï¼ˆé¢„ç•™ï¼‰
â”‚   â”‚
â”‚   â”œâ”€â”€ extraction/            # çŸ¥è¯†æå–æŠ½è±¡ï¼ˆæ–°å¢ï¼‰
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ interfaces.py      # æŠ½è±¡æ¥å£å®šä¹‰
â”‚   â”‚   â”œâ”€â”€ factory.py         # æå–å™¨å·¥å‚
â”‚   â”‚   â””â”€â”€ skill_extractor.py # Skillæå–å™¨å®ç°
â”‚   â”‚
â”‚   â”œâ”€â”€ skill_manager.py       # Skillç®¡ç†å™¨
â”‚   â”œâ”€â”€ skill_validator.py     # SkilléªŒè¯å™¨
â”‚   â”œâ”€â”€ skill_executor.py      # Skillæ‰§è¡Œå™¨
â”‚   â”œâ”€â”€ skill_logger.py        # Skillæ—¥å¿—è®°å½•
â”‚   â”œâ”€â”€ model_router.py        # æ¨¡å‹è·¯ç”±å¼•æ“
â”‚   â”œâ”€â”€ conversation_manager.py # å¯¹è¯ç®¡ç†å™¨
â”‚   â”œâ”€â”€ knowledge_manager.py   # çŸ¥è¯†åº“ç®¡ç†å™¨
â”‚   â”œâ”€â”€ media_processor.py     # åª’ä½“å¤„ç†å™¨
â”‚   â”œâ”€â”€ rss_fetcher.py         # RSSæŠ“å–å™¨
â”‚   â””â”€â”€ exceptions.py          # è‡ªå®šä¹‰å¼‚å¸¸
â”‚
â”œâ”€â”€ models/                     # æ•°æ®æ¨¡å‹ï¼ˆPydanticï¼‰
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py                # åŸºç¡€æ¨¡å‹
â”‚   â”œâ”€â”€ conversation.py        # å¯¹è¯æ¨¡å‹
â”‚   â”œâ”€â”€ document.py            # çŸ¥è¯†æ–‡æ¡£æ¨¡å‹
â”‚   â”œâ”€â”€ media.py               # åª’ä½“æ–‡ä»¶æ¨¡å‹
â”‚   â”œâ”€â”€ rss.py                 # RSSæ¨¡å‹
â”‚   â”œâ”€â”€ log.py                 # æ—¥å¿—æ¨¡å‹
â”‚   â””â”€â”€ config.py              # é…ç½®æ¨¡å‹
â”‚
â”œâ”€â”€ services/                   # æœåŠ¡å±‚ï¼ˆå¤–éƒ¨APIè°ƒç”¨ï¼‰
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ llm_service.py         # LLM APIè°ƒç”¨ï¼ˆSiliconFlowç­‰ï¼‰
â”‚   â”œâ”€â”€ embedding_service.py   # EmbeddingæœåŠ¡
â”‚   â”œâ”€â”€ whisper_service.py     # WhisperæœåŠ¡
â”‚   â””â”€â”€ search_service.py      # æœç´¢æœåŠ¡ï¼ˆSearxngç­‰ï¼‰
â”‚
â”œâ”€â”€ utils/                      # å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ yaml_loader.py         # YAMLåŠ è½½å·¥å…·
â”‚   â”œâ”€â”€ file_utils.py          # æ–‡ä»¶æ“ä½œå·¥å…·
â”‚   â”œâ”€â”€ text_utils.py          # æ–‡æœ¬å¤„ç†å·¥å…·
â”‚   â””â”€â”€ datetime_utils.py      # æ—¶é—´å¤„ç†å·¥å…·
â”‚
â””â”€â”€ tests/                      # æµ‹è¯•ï¼ˆå®é™…åœ¨../test/backend/ï¼‰
    â””â”€â”€ conftest.py            # pytesté…ç½®
```

---

## 4. æ ¸å¿ƒæ¨¡å—è®¾è®¡

### 4.1 é…ç½®ç®¡ç†å™¨ (ConfigManager)
â”‚   â”‚       â””â”€â”€ embeddings.py   # POST /embeddings
â”‚   â”‚
â”‚   â””â”€â”€ admin/                  # åå°ç®¡ç†API
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ v1/
â”‚           â”œâ”€â”€ __init__.py
â”‚           â”œâ”€â”€ dashboard.py    # çœ‹æ¿ç»Ÿè®¡/å¥åº·æ£€æŸ¥
â”‚           â”œâ”€â”€ config.py       # é…ç½®ç®¡ç†
â”‚           â”œâ”€â”€ models.py       # è™šæ‹Ÿæ¨¡å‹CRUD
â”‚           â”œâ”€â”€ skills.py       # Skillç®¡ç†
â”‚           â”œâ”€â”€ conversations.py # å¯¹è¯å†å²
â”‚           â”œâ”€â”€ knowledge.py    # çŸ¥è¯†åº“ç®¡ç†
â”‚           â”œâ”€â”€ media.py        # åª’ä½“å¤„ç†
â”‚           â”œâ”€â”€ rss.py          # RSSè®¢é˜…
â”‚           â”œâ”€â”€ logs.py         # æ—¥å¿—æŸ¥è¯¢
â”‚           â””â”€â”€ raw_data.py     # åŸå§‹æ•°æ®
â”‚
â”œâ”€â”€ core/                       # æ ¸å¿ƒä¸šåŠ¡é€»è¾‘
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py              # é…ç½®ç®¡ç†å™¨
â”‚   â”œâ”€â”€ security.py            # å®‰å…¨å·¥å…·ï¼ˆproxy_keyéªŒè¯ï¼‰
â”‚   â”œâ”€â”€ database.py            # æ•°æ®åº“è¿æ¥ç®¡ç†
â”‚   â”œâ”€â”€ skill_manager.py       # Skillç®¡ç†å™¨
â”‚   â”œâ”€â”€ skill_validator.py     # SkilléªŒè¯å™¨
â”‚   â”œâ”€â”€ skill_executor.py      # Skillæ‰§è¡Œå™¨
â”‚   â”œâ”€â”€ skill_logger.py        # Skillæ—¥å¿—è®°å½•
â”‚   â”œâ”€â”€ model_router.py        # æ¨¡å‹è·¯ç”±å¼•æ“
â”‚   â”œâ”€â”€ conversation_manager.py # å¯¹è¯ç®¡ç†å™¨
â”‚   â”œâ”€â”€ knowledge_manager.py   # çŸ¥è¯†åº“ç®¡ç†å™¨
â”‚   â”œâ”€â”€ media_processor.py     # åª’ä½“å¤„ç†å™¨
â”‚   â”œâ”€â”€ rss_fetcher.py         # RSSæŠ“å–å™¨
â”‚   â””â”€â”€ exceptions.py          # è‡ªå®šä¹‰å¼‚å¸¸
â”‚
â”œâ”€â”€ models/                     # æ•°æ®æ¨¡å‹ï¼ˆPydanticï¼‰
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py                # åŸºç¡€æ¨¡å‹
â”‚   â”œâ”€â”€ conversation.py        # å¯¹è¯æ¨¡å‹
â”‚   â”œâ”€â”€ document.py            # çŸ¥è¯†æ–‡æ¡£æ¨¡å‹
â”‚   â”œâ”€â”€ media.py               # åª’ä½“æ–‡ä»¶æ¨¡å‹
â”‚   â”œâ”€â”€ rss.py                 # RSSæ¨¡å‹
â”‚   â”œâ”€â”€ log.py                 # æ—¥å¿—æ¨¡å‹
â”‚   â””â”€â”€ config.py              # é…ç½®æ¨¡å‹
â”‚
â”œâ”€â”€ services/                   # æœåŠ¡å±‚ï¼ˆå¤–éƒ¨APIè°ƒç”¨ï¼‰
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ llm_service.py         # LLM APIè°ƒç”¨ï¼ˆSiliconFlowç­‰ï¼‰
â”‚   â”œâ”€â”€ embedding_service.py   # EmbeddingæœåŠ¡
â”‚   â”œâ”€â”€ whisper_service.py     # WhisperæœåŠ¡
â”‚   â””â”€â”€ search_service.py      # æœç´¢æœåŠ¡ï¼ˆSearxngç­‰ï¼‰
â”‚
â”œâ”€â”€ utils/                      # å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ yaml_loader.py         # YAMLåŠ è½½å·¥å…·
â”‚   â”œâ”€â”€ file_utils.py          # æ–‡ä»¶æ“ä½œå·¥å…·
â”‚   â”œâ”€â”€ text_utils.py          # æ–‡æœ¬å¤„ç†å·¥å…·
â”‚   â””â”€â”€ datetime_utils.py      # æ—¶é—´å¤„ç†å·¥å…·
â”‚
â””â”€â”€ tests/                      # æµ‹è¯•ï¼ˆå®é™…åœ¨../test/backend/ï¼‰
    â””â”€â”€ conftest.py            # pytesté…ç½®
```

---

### 4.1 é…ç½®ç®¡ç†å™¨ (ConfigManager)

**èŒè´£**: ç®¡ç†config.ymlçš„è¯»å–ã€éªŒè¯ã€çƒ­é‡è½½

**ç±»è®¾è®¡**:
```python
class ConfigManager:
    _instance = None
    _config: Dict[str, Any] = {}
    _file_path: str = "./config.yml"
    _last_modified: float = 0
    
    def __new__(cls):
        # å•ä¾‹æ¨¡å¼
        
    def load_config(self) -> Dict[str, Any]:
        # åŠ è½½YAMLæ–‡ä»¶
        
    def validate_config(self, config: Dict[str, Any]) -> Tuple[bool, List[str]]:
        """
        éªŒè¯é…ç½®ï¼ˆå ä½å®ç°ï¼‰
        
        æ­¤æ–¹æ³•ä¸ºæŠ€èƒ½é…ç½®éªŒè¯çš„å ä½å®ç°ï¼Œå¾…æŠ€èƒ½ç³»ç»Ÿå®Œå–„åå†å®ç°å…·ä½“é€»è¾‘ã€‚
        å½“å‰ç›´æ¥è¿”å›éªŒè¯é€šè¿‡ã€‚
        
        Args:
            config: é…ç½®å­—å…¸
            
        Returns:
            Tuple[bool, List[str]]: (æ˜¯å¦é€šè¿‡, é”™è¯¯ä¿¡æ¯åˆ—è¡¨)
        """
        # å ä½å®ç°ï¼šå¾…æŠ€èƒ½ç³»ç»Ÿå®Œå–„åå®ç°å…·ä½“éªŒè¯é€»è¾‘
        return True, []
        
    def reload_config(self) -> bool:
        # çƒ­é‡è½½é…ç½®
        
    def get(self, key: str, default=None) -> Any:
        # è·å–é…ç½®é¡¹ï¼ˆæ”¯æŒç‚¹å·è·¯å¾„ï¼‰
        # å¦‚: get("ai-gateway.virtual_models.demo1.small.api_key")
        
    def set(self, key: str, value: Any) -> bool:
        # è®¾ç½®é…ç½®é¡¹å¹¶ä¿å­˜åˆ°æ–‡ä»¶
        
    def watch_config(self):
        # ä½¿ç”¨watchdogç›‘å¬æ–‡ä»¶å˜åŒ–
```

**é…ç½®ç»“æ„** (å¯¹åº”config.yml):
```python
class AppConfig(BaseModel):
    host: str = "127.0.0.1"
    port: int = 8000
    debug: bool = False

class StorageConfig(BaseModel):
    mongodb: MongoDBConfig
    qdrant: QdrantConfig
    redis: RedisConfig

class ModelConfig(BaseModel):
    """å•ä¸ªæ¨¡å‹é…ç½®ï¼ˆå¯æ‰©å±•ï¼‰"""
    name: str  # æ¨¡å‹åç§°ï¼ˆå¦‚ deepseek-ai/DeepSeek-V3ï¼‰
    api_key: Optional[str] = None
    base_url: Optional[str] = None
    provider: str = "siliconflow"  # æä¾›å•†
    priority: int = 1  # æ˜¾ç¤ºä¼˜å…ˆçº§

class KeywordRule(BaseModel):
    """å…³é”®è¯è§„åˆ™"""
    pattern: str  # åŒ¹é…æ¨¡å¼
    target: str  # ç›®æ ‡æ¨¡å‹IDï¼ˆä»»æ„å­—ç¬¦ä¸²ï¼Œä¸é™äºsmall/bigï¼‰

class KeywordSwitchingConfig(BaseModel):
    """å…³é”®è¯åˆ‡æ¢é…ç½®"""
    enabled: bool = False
    rules: List[KeywordRule] = Field(default_factory=list)

class RoutingConfig(BaseModel):
    """è·¯ç”±é…ç½®ï¼ˆæ ¸å¿ƒå¯æ‰©å±•éƒ¨åˆ†ï¼‰"""
    current: str = "small"  # å½“å‰é»˜è®¤æ¨¡å‹IDï¼ˆä»»æ„å­—ç¬¦ä¸²ï¼‰
    force_current: bool = False  # æ˜¯å¦å¼ºåˆ¶
    models: Dict[str, ModelConfig] = Field(default_factory=dict)  # åŠ¨æ€æ¨¡å‹åˆ—è¡¨
    keyword_switching: KeywordSwitchingConfig = Field(default_factory=KeywordSwitchingConfig)

class KeywordConfig(BaseModel):
    """å…³é”®è¯æ¨¡å‹åˆ‡æ¢é…ç½®ï¼ˆä¼ ç»Ÿæ–¹å¼ï¼‰"""
    enabled: bool = False
    small_keywords: List[str] = Field(default_factory=list, max_length=50)
    big_keywords: List[str] = Field(default_factory=list, max_length=50)


class RoutingKeywordsConfig(BaseModel):
    """è·¯ç”±å…³é”®è¯é…ç½®ï¼ˆæ–°æ–¹å¼ï¼‰"""
    enable: bool = False  # æ³¨æ„ï¼šä½¿ç”¨enableä¸æ˜¯enabled
    rules: List[KeywordRule] = Field(default_factory=list)


class RoutingSkillConfig(BaseModel):
    """è·¯ç”±Skillé…ç½®"""
    enabled: bool = True
    version: str = "v1"
    custom: Dict[str, Any] = Field(default_factory=lambda: {"enabled": False, "version": "v2"})


class RoutingConfig(BaseModel):
    """è™šæ‹Ÿæ¨¡å‹è·¯ç”±é…ç½®ï¼ˆæ›¿ä»£å…¨å±€routerï¼‰"""
    keywords: RoutingKeywordsConfig = Field(default_factory=RoutingKeywordsConfig)
    skill: RoutingSkillConfig = Field(default_factory=RoutingSkillConfig)


class VirtualModelConfig(BaseModel):
    """è™šæ‹Ÿæ¨¡å‹é…ç½® - å¯¹åº”å®é™…ä»£ç å®ç°"""
    name: str
    proxy_key: str
    base_url: Optional[str] = None
    current: Literal["small", "big"] = "small"  # å½“å‰é»˜è®¤æ¨¡å‹
    force_current: bool = False  # æ˜¯å¦å¼ºåˆ¶ä½¿ç”¨å½“å‰æ¨¡å‹
    stream_support: bool = True  # æ˜¯å¦æ”¯æŒæµå¼è¿”å›
    use: bool = True  # æ˜¯å¦å¯ç”¨
    
    # æ¨¡å‹é…ç½®ï¼ˆå›ºå®šsmall/bigä¸¤ä¸ªæ¨¡å‹ï¼‰
    small: ModelConfig = Field(default_factory=ModelConfig)
    big: ModelConfig = Field(default_factory=ModelConfig)
    
    # æ–°å¢ï¼šè™šæ‹Ÿæ¨¡å‹ç‹¬ç«‹è·¯ç”±é…ç½®
    routing: RoutingConfig = Field(default_factory=RoutingConfig)
    
    # ä¼ ç»Ÿå…³é”®è¯åˆ‡æ¢é…ç½®ï¼ˆä¸routing.keywordså¹¶å­˜ï¼‰
    keyword_switching: KeywordConfig = Field(default_factory=KeywordConfig)
    
    # åŠŸèƒ½é…ç½®
    knowledge: KnowledgeConfig = Field(default_factory=KnowledgeConfig)
    web_search: WebSearchConfig = Field(default_factory=WebSearchConfig)

class AIGatewayConfig(BaseModel):
    router: RouterConfig
    virtual_models: Dict[str, VirtualModelConfig]
    knowledge: KnowledgeConfig
    rss: RSSConfig
    media: MediaConfig
    log: LogConfig
```

---

### 3.2 Skillç®¡ç†å™¨ (SkillManager)

**èŒè´£**: Skillçš„å‘ç°ã€åŠ è½½ã€éªŒè¯ã€æ‰§è¡Œã€é‡è½½ï¼›æ”¯æŒå¤šSkillç®¡ç†å’Œå¤šç‰ˆæœ¬æ§åˆ¶

**ç›®å½•ç»“æ„**:
```
skills/
â”œâ”€â”€ system/
â”‚   â””â”€â”€ router/
â”‚       â””â”€â”€ v1/
â”‚           â”œâ”€â”€ å…³é”®è¯è·¯ç”±/
â”‚           â”‚   â””â”€â”€ SKILL.md
â”‚           â””â”€â”€ æ„å›¾è¯†åˆ«/
â”‚               â””â”€â”€ SKILL.md
â”œâ”€â”€ custom/
â”‚   â””â”€â”€ router/
â”‚       â”œâ”€â”€ v1/
â”‚       â”‚   â””â”€â”€ X_skill/
â”‚       â”‚       â””â”€â”€ SKILL.md
â”‚       â””â”€â”€ v2/
â”‚           â””â”€â”€ X_skill/
â”‚               â””â”€â”€ SKILL.md
â”‚       â””â”€â”€ v1/
â”‚           â””â”€â”€ Y_skill/
â”‚               â””â”€â”€ SKILL.md
```

**ç±»è®¾è®¡**:
```python
class SkillManager:
    _skills: Dict[str, Dict[str, SkillVersions]] = {}  # category -> {name -> versions}
    _config_manager: ConfigManager
    
    def __init__(self, config_manager: ConfigManager):
        self._config_manager = config_manager
        self._load_all_skills()
    
    def _load_all_skills(self):
        # éå†skill/system/å’Œskill/custom/ç›®å½•
        # åŠ è½½æ‰€æœ‰åˆ†ç±»ã€æ‰€æœ‰Skillã€æ‰€æœ‰ç‰ˆæœ¬
        # ç»“æ„: category -> skill_name -> {version -> SkillInfo}
        
    def _load_skill(self, category: str, name: str, 
                    is_custom: bool, version: str) -> Optional[SkillInfo]:
        # åŠ è½½å•ä¸ªSkillçš„ç‰¹å®šç‰ˆæœ¬
        # 1. è¯»å–SKILL.md
        # 2. éªŒè¯YAML frontmatter
        # 3. å¦‚æœæœ‰.pyæ–‡ä»¶ï¼ŒåŠ¨æ€å¯¼å…¥
        
    def get_skill(self, category: str, name: str, 
                  version: Optional[str] = None) -> Optional[SkillInfo]:
        # è·å–Skillä¿¡æ¯
        # å¦‚æœä¸æŒ‡å®šversionï¼Œè¿”å›å½“å‰æ¿€æ´»ç‰ˆæœ¬
        
    def get_skills_by_category(self, category: str) -> List[SkillSummary]:
        # è·å–æŸåˆ†ç±»ä¸‹æ‰€æœ‰Skillåˆ—è¡¨
        # åŒ…æ‹¬ç³»ç»Ÿé»˜è®¤å’Œè‡ªå®šä¹‰Skills
        
    def get_skill_versions(self, category: str, name: str,
                          is_custom: bool) -> List[str]:
        # è·å–æŒ‡å®šSkillçš„æ‰€æœ‰å¯ç”¨ç‰ˆæœ¬
        
    async def execute(self, category: str, name: str, 
                     version: Optional[str] = None,
                     **kwargs) -> Dict[str, Any]:
        # æ‰§è¡ŒSkill
        # 1. éªŒè¯è¾“å…¥å‚æ•°ï¼ˆJSON Schemaï¼‰
        # 2. è°ƒç”¨æ‰§è¡Œå‡½æ•°
        # 3. éªŒè¯è¾“å‡ºç»“æœï¼ˆJSON Schemaï¼‰
        # 4. è®°å½•æ‰§è¡Œæ—¥å¿—
        # 5. è¿”å›ç»“æœ
        
    def create_skill(self, category: str, name: str,
                     version: str, content: str,
                     copy_from: Optional[str] = None) -> bool:
        # åˆ›å»ºæ–°çš„è‡ªå®šä¹‰Skill
        # 1. æ£€æŸ¥åç§°æ˜¯å¦å·²å­˜åœ¨ï¼ˆåŒä¸€åˆ†ç±»ï¼‰
        # 2. åˆ›å»ºç›®å½•ç»“æ„
        # 3. å†™å…¥SKILL.md
        # 4. åŠ è½½å¹¶éªŒè¯
        
    def create_version(self, category: str, name: str,
                       new_version: str, copy_from: str) -> bool:
        # ä¸ºç°æœ‰Skillåˆ›å»ºæ–°ç‰ˆæœ¬
        # 1. å¤åˆ¶æŒ‡å®šç‰ˆæœ¬å†…å®¹
        # 2. æ›´æ–°ç‰ˆæœ¬å·
        # 3. ä¿å­˜åˆ°æ–°ç›®å½•
        
    def update_skill(self, category: str, name: str,
                     version: str, content: str) -> bool:
        # æ›´æ–°æŒ‡å®šç‰ˆæœ¬çš„Skillå†…å®¹
        # 1. éªŒè¯å†…å®¹æ ¼å¼
        # 2. å¤‡ä»½åŸæ–‡ä»¶
        # 3. å†™å…¥æ–°å†…å®¹
        # 4. é‡æ–°åŠ è½½
        
    def delete_skill(self, category: str, name: str,
                     is_custom: bool) -> bool:
        # åˆ é™¤æ•´ä¸ªSkillï¼ˆæ‰€æœ‰ç‰ˆæœ¬ï¼‰
        # ä»…å…è®¸åˆ é™¤è‡ªå®šä¹‰Skill
        
    def delete_version(self, category: str, name: str,
                       version: str) -> bool:
        # åˆ é™¤æŒ‡å®šç‰ˆæœ¬
        # ä¸èƒ½åˆ é™¤å½“å‰æ¿€æ´»ç‰ˆæœ¬
        
    def reload_skill(self, category: str, name: str) -> bool:
        # é‡è½½å•ä¸ªSkillçš„æ‰€æœ‰ç‰ˆæœ¬
        
    def reload_all(self) -> Dict[str, int]:
        # é‡è½½æ‰€æœ‰Skill
        # è¿”å›ç»Ÿè®¡ä¿¡æ¯ï¼šæˆåŠŸæ•°ã€å¤±è´¥æ•°
        
    def validate_skill(self, content: str) -> ValidationResult:
        # æ ¡éªŒSkillå†…å®¹
        # è¿”å›ï¼šæ˜¯å¦é€šè¿‡ã€é”™è¯¯åˆ—è¡¨ã€è­¦å‘Šåˆ—è¡¨
```

**Skillä¿¡æ¯ç»“æ„**:
```python
class SkillMetadata(BaseModel):
    name: str
    description: str
    type: Literal["rule-based", "llm-based", "hybrid"]
    priority: int = 1
    version: str
    input_schema: Dict[str, Any]
    output_schema: Dict[str, Any]
    # LLM-basedç‰¹æœ‰
    model: Optional[str] = None
    # Rule-basedç‰¹æœ‰
    rules: Optional[List[Dict]] = None

class SkillInfo:
    category: str
    name: str
    metadata: SkillMetadata
    is_custom: bool
    version: str
    file_path: str
    has_py_file: bool
    execute_func: Optional[Callable] = None
    created_at: datetime
    updated_at: datetime

class SkillSummary:
    # ç”¨äºåˆ—è¡¨å±•ç¤º
    category: str
    name: str
    is_custom: bool
    current_version: str
    all_versions: List[str]
    description: str
    enabled: bool

class ValidationResult:
    valid: bool
    errors: List[ValidationError]
    warnings: List[ValidationWarning]

class ValidationError:
    line: int
    column: int
    message: str
    field: Optional[str]  # å¦‚ "name", "input_schema.properties.x"

class ValidationWarning:
    line: int
    message: str
    suggestion: str
```

---

### 3.3 æ¨¡å‹è·¯ç”±å¼•æ“ (ModelRouter)

**èŒè´£**: æ ¹æ®è¾“å…¥å†³å®šä½¿ç”¨å¤§æ¨¡å‹è¿˜æ˜¯å°æ¨¡å‹

**ç±»è®¾è®¡**:
```python
class ModelRouter:
    _skill_manager: SkillManager
    _config_manager: ConfigManager
    _redis: Redis
    
    def __init__(self, skill_manager, config_manager, redis):
        self._skill_manager = skill_manager
        self._config_manager = config_manager
        self._redis = redis
    
    async def route(self, virtual_model: str, 
                   user_input: str,
                   conversation_id: Optional[str] = None) -> RouteResult:
        # æ¨¡å‹è·¯ç”±å†³ç­–
        # 1. æ£€æŸ¥æ˜¯å¦å¼ºåˆ¶æ¨¡å¼
        config = self._config_manager.get(f"ai-gateway.virtual_models.{virtual_model}")
        if config.get("force_current"):
            return RouteResult(model_type=config["current"], reason="å¼ºåˆ¶æ¨¡å¼")
        
        # 2. è·å–ä¼šè¯ä¸Šä¸‹æ–‡
        context = await self._get_conversation_context(conversation_id)
        
        # 3. å°è¯•å…³é”®è¯è·¯ç”±ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
        keyword_result = await self._try_keyword_router(user_input)
        if keyword_result:
            return keyword_result
        
        # 4. å°è¯•æ„å›¾è¯†åˆ«è·¯ç”±
        intent_result = await self._try_intent_router(user_input, context)
        if intent_result and intent_result.confidence > 0.8:
            return intent_result
        
        # 5. ä½¿ç”¨é»˜è®¤æ¨¡å‹
        return RouteResult(
            model_type=config["current"],
            reason=f"ç½®ä¿¡åº¦{intent_result.confidence if intent_result else 'N/A'}è¿‡ä½ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹"
        )
    
    async def _try_keyword_router(self, user_input: str) -> Optional[RouteResult]:
        # æ‰§è¡Œå…³é”®è¯è·¯ç”±Skill
        result = await self._skill_manager.execute(
            "router", "å…³é”®è¯è·¯ç”±",
            user_input=user_input
        )
        if result.get("target"):
            return RouteResult(
                model_type=result["target"],
                matched_rule=result.get("matched_rule"),
                reason=f"å…³é”®è¯åŒ¹é…: {result.get('matched_rule')}"
            )
        return None
    
    async def _try_intent_router(self, user_input: str, 
                                 context: str) -> Optional[RouteResult]:
        # æ‰§è¡Œæ„å›¾è¯†åˆ«Skill
        result = await self._skill_manager.execute(
            "router", "æ„å›¾è¯†åˆ«",
            user_input=user_input,
            context=context
        )
        if result.get("model_type") and not result.get("fallback"):
            return RouteResult(
                model_type=result["model_type"],
                confidence=result.get("confidence", 0),
                reason=result.get("reason", "")
            )
        return None
```

---

### 3.4 å¯¹è¯ç®¡ç†å™¨ (ConversationManager)

**èŒè´£**: å¯¹è¯çš„åˆ›å»ºã€æŸ¥è¯¢ã€ä¿å­˜ã€åˆ é™¤

**ç±»è®¾è®¡**:

---

### 3.5 å¯¹è¯å¤„ç†ç®¡é“ï¼ˆChat Pipelineï¼‰

**èŒè´£**: ä½¿ç”¨èŒè´£é“¾æ¨¡å¼ï¼ˆChain of Responsibilityï¼‰å¤„ç†å¯¹è¯è¯·æ±‚ï¼Œå®ç°å¯æ‰©å±•çš„å¯¹è¯å¤„ç†æµç¨‹ã€‚

**è§£å†³çš„é—®é¢˜**:
- å½“å‰ `chat.py` ä¸€ä¸ªå‡½æ•°å¤„ç†æ‰€æœ‰é€»è¾‘ï¼Œéš¾ä»¥ç»´æŠ¤å’Œæ‰©å±•
- å¯¹è¯å†å²ä¿å­˜é€»è¾‘æ•£è½åœ¨å„å¤„ï¼Œå®¹æ˜“é—æ¼
- æ— æ³•çµæ´»æ·»åŠ é¢„å¤„ç†ï¼ˆçŸ¥è¯†æ£€ç´¢ã€è”ç½‘æœç´¢ï¼‰å’Œåå¤„ç†ï¼ˆå‹ç¼©ã€æ€»ç»“ï¼‰

**è®¾è®¡å†³ç­–**:
- **å“åº”æ–¹å¼**: ç»Ÿä¸€éæµå¼ï¼ˆä¸€æ¬¡è¿”å›å®Œæ•´å“åº”ï¼‰ï¼Œç®€åŒ–å¤„ç†é€»è¾‘
- **é”™è¯¯å¤„ç†**: å³ä½¿LLMè°ƒç”¨å¤±è´¥ï¼Œä¹Ÿè¦ä¿å­˜ç”¨æˆ·æ¶ˆæ¯ï¼Œç¡®ä¿æ•°æ®ä¸ä¸¢å¤±
- **Rawæ•°æ®å½’æ¡£**: æ°¸ä¹…ä¿ç•™å®Œæ•´è¯·æ±‚/å“åº”ï¼Œæ ¹æ® `config.yml` ä¸­ `log.system.retention.days` è‡ªåŠ¨æ¸…ç†
- **é¢„ç•™æ¥å£**: Knowledgeå’ŒWebSearché¢„ç•™ï¼Œè¯»å–é…ç½®ä½†ä¸å®ç°æ ¸å¿ƒé€»è¾‘
- **4getæœç´¢**: ä¿ç•™ç©ºç›®å½•ï¼Œä»£ç ä¸­åšç©ºå®ç°

#### 3.5.1 èŒè´£é“¾æ‰§è¡Œæµç¨‹

```
Phase 1: è¾“å…¥å¤„ç†å±‚ï¼ˆå¿…é¡»ï¼‰
  1. InputValidatorHandler       - è¾“å…¥éªŒè¯ã€å®‰å…¨è¿‡æ»¤
  2. UserMessagePersistence     - ğŸ’¾ ä¿å­˜ç”¨æˆ·åŸå§‹æé—®ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰

Phase 2: é¢„å¤„ç†å±‚ï¼ˆé¢„ç•™æ¥å£ï¼‰
  3. KnowledgeRetrievalHandler  - ğŸ“š çŸ¥è¯†åº“æ£€ç´¢ï¼ˆé¢„ç•™ï¼Œè¯»å–é…ç½®ï¼‰
  4. WebSearchHandler           - ğŸ” è”ç½‘æœç´¢ï¼ˆé¢„ç•™ï¼Œè¯»å–é…ç½®ï¼Œ4getç©ºå®ç°ï¼‰

Phase 3: æ¨¡å‹å±‚ï¼ˆå¿…é¡»ï¼‰
  5. ModelRoutingHandler        - ğŸ¯ æ¨¡å‹è·¯ç”±å†³ç­–
  6. LLMInvocationHandler       - ğŸ¤– è°ƒç”¨è¿œç¨‹LLMï¼ˆå·²å®Œæ•´å®ç°ï¼‰

Phase 4: åå¤„ç†å±‚ï¼ˆå¿…é¡»+å½’æ¡£ï¼‰
  7. AssistantMessagePersistence - ğŸ’¾ ä¿å­˜åŠ©æ‰‹å›å¤
  8. RawDataArchiveHandler      - ğŸ“¦ å®Œæ•´æ•°æ®å½’æ¡£ï¼ˆæ°¸ä¹…ä¿ç•™ï¼‰

Phase 5: è¾“å‡ºå±‚ï¼ˆå¿…é¡»ï¼‰
  9. ResponseFormatter          - ğŸ“¤ æ ¼å¼åŒ–JSONå“åº”
```

**é‡è¦è¯´æ˜**ï¼š
- **ç»Ÿä¸€å…¥å£**: æ‰€æœ‰å®¢æˆ·ç«¯ï¼ˆWebChat/ChatBox/ç¬¬ä¸‰æ–¹APIï¼‰éƒ½é€šè¿‡ `/proxy/ai/v1/chat/completions` æ¥å£è®¿é—®ï¼Œç»Ÿä¸€ç»è¿‡èŒè´£é“¾å¤„ç†
- **è‡ªåŠ¨ä¿å­˜**: ç”¨æˆ·æ¶ˆæ¯å’ŒåŠ©æ‰‹å›å¤åœ¨èŒè´£é“¾ä¸­è‡ªåŠ¨ä¿å­˜åˆ°MongoDBï¼Œå‰ç«¯æ— éœ€æ‰‹åŠ¨è°ƒç”¨ä¿å­˜API
- **å®Œæ•´å®ç°**: LLMInvocationHandler å·²å®Œæ•´å®ç°ï¼Œæ”¯æŒ OpenAI/SiliconFlow/Ollama ä¸‰ç§æä¾›å•†

#### 3.5.2 æ ¸å¿ƒç±»è®¾è®¡

```python
# core/chat_pipeline.py

from typing import Optional, List, Dict, Any
from dataclasses import dataclass, field
from datetime import datetime
import time
import uuid


@dataclass
class ChatContext:
    """å¯¹è¯ä¸Šä¸‹æ–‡ - åœ¨èŒè´£é“¾ä¸­ä¼ é€’"""
    # è¾“å…¥
    conversation_id: Optional[str] = None
    virtual_model: str = ""
    messages: List[Dict[str, Any]] = field(default_factory=list)
    user_message: str = ""
    stream: bool = False
    temperature: float = 0.7
    max_tokens: int = 2000
    
    # å¤„ç†ç»“æœ
    model_type: Optional[str] = None  # "small" | "big"
    model_config: Optional[Dict] = None
    response_content: str = ""
    
    # å…ƒæ•°æ®
    metadata: Dict[str, Any] = field(default_factory=dict)
    request_id: str = field(default_factory=lambda: str(uuid.uuid4())[:8])
    start_time: float = field(default_factory=time.time)
    user_message_saved: bool = False
    error_occurred: bool = False
    skip_reason: Optional[str] = None


class PipelineHandler:
    """å¤„ç†å™¨åŸºç±»"""
    
    def __init__(self, name: str):
        self.name = name
        self._next: Optional['PipelineHandler'] = None
    
    def set_next(self, handler: 'PipelineHandler') -> 'PipelineHandler':
        """è®¾ç½®ä¸‹ä¸€ä¸ªå¤„ç†å™¨"""
        self._next = handler
        return handler
    
    async def handle(self, context: ChatContext) -> ChatContext:
        """å¤„ç†é€»è¾‘"""
        context = await self._process(context)
        
        # å¦‚æœæ²¡æœ‰è·³è¿‡åç»­å¤„ç†çš„æ ‡è®°ï¼Œç»§ç»­æ‰§è¡Œé“¾
        if self._next and not context.skip_reason and not context.error_occurred:
            return await self._next.handle(context)
        return context
    
    async def _process(self, context: ChatContext) -> ChatContext:
        """å­ç±»å®ç°å…·ä½“é€»è¾‘"""
        raise NotImplementedError


class ChatPipeline:
    """å¯¹è¯ç®¡é“ - ç»„è£…èŒè´£é“¾"""
    
    def __init__(
        self,
        conversation_manager,
        skill_manager,
        config_manager,
        knowledge_manager=None,
        model_router=None
    ):
        self._cm = conversation_manager
        self._sm = skill_manager
        self._config = config_manager
        self._km = knowledge_manager
        self._router = model_router
        
        # æ„å»ºèŒè´£é“¾
        self._chain = self._build_chain()
    
    def _build_chain(self) -> PipelineHandler:
        """æ„å»ºå¤„ç†é“¾"""
        
        # Phase 1: è¾“å…¥å¤„ç†
        validator = InputValidatorHandler()
        user_persistence = UserMessagePersistence(self._cm)
        
        # Phase 2: é¢„å¤„ç†ï¼ˆé¢„ç•™æ¥å£ï¼‰
        knowledge = KnowledgeRetrievalHandler(self._config, self._sm)
        web_search = WebSearchHandler(self._config, self._sm)
        
        # Phase 3: æ¨¡å‹å±‚
        routing = ModelRoutingHandler(self._router, self._config)
        llm = LLMInvocationHandler(self._config)
        
        # Phase 4: åå¤„ç†
        assistant_persistence = AssistantMessagePersistence(self._cm)
        raw_archive = RawDataArchiveHandler(self._cm)
        
        # Phase 5: è¾“å‡º
        formatter = ResponseFormatter()
        
        # ç»„è£…é“¾æ¡
        validator.set_next(user_persistence) \
                 .set_next(knowledge) \
                 .set_next(web_search) \
                 .set_next(routing) \
                 .set_next(llm) \
                 .set_next(assistant_persistence) \
                 .set_next(raw_archive) \
                 .set_next(formatter)
        
        return validator
    
    async def process(self, context: ChatContext) -> ChatContext:
        """æ‰§è¡Œç®¡é“å¤„ç†"""
        return await self._chain.handle(context)
```

#### 3.5.3 æ ¸å¿ƒHandlerå®ç°

**UserMessagePersistence**ï¼ˆæœ€å…ˆæ‰§è¡Œï¼Œç¡®ä¿ä¸ä¸¢å¤±ï¼‰:

```python
class UserMessagePersistence(PipelineHandler):
    """ä¿å­˜ç”¨æˆ·åŸå§‹æé—® - æœ€é«˜ä¼˜å…ˆçº§"""
    
    def __init__(self, conversation_manager):
        super().__init__("UserMessagePersistence")
        self._cm = conversation_manager
    
    async def _process(self, context: ChatContext) -> ChatContext:
        # ç¡®ä¿æœ‰conversation_id
        if not context.conversation_id:
            context.conversation_id = await self._cm.create_conversation(
                context.virtual_model
            )
        
        # ç«‹å³ä¿å­˜ç”¨æˆ·æ¶ˆæ¯ï¼ˆä¸ç­‰å¾…åç»­å¤„ç†ï¼‰
        await self._cm.add_message(
            conversation_id=context.conversation_id,
            role="user",
            content=context.user_message,
            metadata={
                "timestamp": datetime.utcnow().isoformat(),
                "request_id": context.request_id,
                "source": "webchat",
                "ip": context.metadata.get("client_ip")
            }
        )
        
        context.user_message_saved = True
        logger.info(f"ğŸ’¾ [{context.request_id}] ç”¨æˆ·æ¶ˆæ¯å·²æŒä¹…åŒ–: {context.conversation_id}")
        return context
```

**KnowledgeRetrievalHandler**ï¼ˆé¢„ç•™æ¥å£ï¼‰:

```python
class KnowledgeRetrievalHandler(PipelineHandler):
    """çŸ¥è¯†åº“æ£€ç´¢ - å½“å‰é¢„ç•™æ¥å£ï¼Œè¯»å–é…ç½®ä½†ä¸å®ç°æ ¸å¿ƒé€»è¾‘"""
    
    def __init__(self, config_manager, skill_manager):
        super().__init__("KnowledgeRetrievalHandler")
        self._config = config_manager
        self._sm = skill_manager
    
    def _get_knowledge_config(self, virtual_model: str) -> Dict:
        """ä»config.ymlè¯»å–çŸ¥è¯†åº“é…ç½®"""
        return self._config.get(
            f"ai-gateway.virtual_models.{virtual_model}.knowledge", 
            {}
        )
    
    async def _process(self, context: ChatContext) -> ChatContext:
        # è¯»å–é…ç½®
        config = self._get_knowledge_config(context.virtual_model)
        
        if not config.get("enabled", False):
            return context  # æœªå¯ç”¨ï¼Œç›´æ¥è·³è¿‡
        
        # é¢„ç•™ï¼šæ£€æŸ¥Skillé…ç½®
        skill_config = config.get("skill", {})
        if skill_config.get("enabled") and skill_config.get("version"):
            # é¢„ç•™è°ƒç”¨Skillçš„ä»£ç ï¼Œå½“å‰ä¸å®ç°
            # result = await self._sm.execute(
            #     "knowledge", f"æ£€ç´¢/{skill_config['version']}",
            #     query=context.user_message
            # )
            pass
        
        # è®°å½•å…ƒæ•°æ®
        context.metadata["knowledge_checked"] = True
        context.metadata["knowledge_enabled"] = True
        context.metadata["knowledge_skill_version"] = skill_config.get("version")
        
        logger.info(f"ğŸ“š [{context.request_id}] çŸ¥è¯†åº“æ£€ç´¢å·²é¢„ç•™ï¼ˆé…ç½®å¯ç”¨ï¼Œæš‚æœªå®ç°ï¼‰")
        return context
```

**WebSearchHandler**ï¼ˆé¢„ç•™æ¥å£ï¼Œ4getç©ºå®ç°ï¼‰:

```python
class WebSearchHandler(PipelineHandler):
    """è”ç½‘æœç´¢ - é¢„ç•™æ¥å£ï¼Œ4getç©ºå®ç°"""
    
    def __init__(self, config_manager, skill_manager):
        super().__init__("WebSearchHandler")
        self._config = config_manager
        self._sm = skill_manager
    
    def _get_web_search_config(self, virtual_model: str) -> Dict:
        """ä»config.ymlè¯»å–è”ç½‘æœç´¢é…ç½®"""
        return self._config.get(
            f"ai-gateway.virtual_models.{virtual_model}.web_search",
            {}
        )
    
    async def _process(self, context: ChatContext) -> ChatContext:
        config = self._get_web_search_config(context.virtual_model)
        
        if not config.get("enabled", False):
            return context
        
        targets = config.get("target", [])
        
        # 4get ç©ºå®ç°ï¼ˆä¿ç•™ç›®å½•ï¼‰
        if "4get" in targets:
            logger.info(f"ğŸ” [{context.request_id}] 4getæœç´¢ - ç©ºå®ç°ï¼ˆç›®å½•ä¿ç•™ï¼‰")
        
        # LibreX é¢„ç•™
        if "LibreX" in targets:
            logger.info(f"ğŸ” [{context.request_id}] LibreXæœç´¢ - é¢„ç•™æ¥å£")
        
        # Skillé¢„ç•™
        skill_config = config.get("skill", {})
        if skill_config.get("enabled"):
            logger.info(f"ğŸ” [{context.request_id}] WebSearch Skillé¢„ç•™ï¼ˆç‰ˆæœ¬: {skill_config.get('version')}ï¼‰")
        
        context.metadata["web_search_checked"] = True
        context.metadata["web_search_targets"] = targets
        
        return context
```

**ModelRoutingHandler**ï¼ˆæ¨¡å‹è·¯ç”± + å…³é”®è¯æ›¿æ¢ï¼‰:

```python
class ModelRoutingHandler(PipelineHandler):
    """æ¨¡å‹è·¯ç”±å†³ç­–å¤„ç†å™¨ - åŒ…å«å…³é”®è¯åŒ¹é…å’Œæ›¿æ¢åŠŸèƒ½"""
    
    def __init__(self, model_router, config_manager=None):
        super().__init__("ModelRoutingHandler")
        self._router = model_router
        self._config = config_manager
    
    def _get_keyword_config(self, virtual_model: str) -> Dict:
        """ä»config.ymlè¯»å–å…³é”®è¯è·¯ç”±é…ç½®"""
        return self._config.get(
            f"ai-gateway.virtual_models.{virtual_model}.routing.keywords",
            {}
        )
    
    async def _process(self, context: ChatContext) -> ChatContext:
        """æ‰§è¡Œæ¨¡å‹è·¯ç”±å†³ç­– + å…³é”®è¯æ›¿æ¢"""
        
        # 1. é¦–å…ˆå°è¯•å…³é”®è¯åŒ¹é…å’Œæ›¿æ¢
        keyword_config = self._get_keyword_config(context.virtual_model)
        
        if keyword_config.get("enabled", False):
            rules = keyword_config.get("rules", [])
            
            for rule in rules:
                pattern = rule.get("pattern", "")
                target = rule.get("target", "small")
                
                if pattern in context.user_message:
                    # åŒ¹é…æˆåŠŸï¼šåˆ‡æ¢æ¨¡å‹
                    context.model_type = target
                    context.metadata["model_type"] = target
                    context.metadata["route_reason"] = f"å…³é”®è¯åŒ¹é…: {pattern}"
                    context.metadata["matched_keyword"] = pattern
                    
                    # è®°å½•åŸå§‹æ¶ˆæ¯
                    context.metadata["original_user_message"] = context.user_message
                    
                    # ç§»é™¤å…³é”®è¯
                    context.user_message = context.user_message.replace(pattern, "").strip()
                    context.metadata["processed_user_message"] = context.user_message
                    
                    logger.info(f"ğŸ¯ [{context.request_id}] å…³é”®è¯åŒ¹é…: {pattern} -> {target}")
                    logger.info(f"ğŸ“ [{context.request_id}] æ¶ˆæ¯æ›¿æ¢: '{pattern}' -> ''")
                    logger.info(f"ğŸ“ [{context.request_id}] æœ€ç»ˆæ¶ˆæ¯: '{context.user_message}'")
                    
                    # åŒ¹é…æˆåŠŸï¼Œè·³è¿‡åç»­çš„ModelRouter.route()è°ƒç”¨
                    return context
        
        # 2. å¦‚æœæ²¡æœ‰åŒ¹é…å…³é”®è¯ï¼Œç»§ç»­åŸæœ‰ModelRouter.route()é€»è¾‘
        try:
            route_result = await self._router.route(
                virtual_model=context.virtual_model,
                user_input=context.user_message,
                conversation_id=context.conversation_id
            )
            
            context.model_type = route_result.model_type
            context.metadata["model_type"] = route_result.model_type
            context.metadata["route_reason"] = route_result.reason
            context.metadata["route_confidence"] = route_result.confidence
            context.metadata["matched_rule"] = route_result.matched_rule
            
            logger.info(f"ğŸ¯ [{context.request_id}] è·¯ç”±å†³ç­–: {route_result.model_type} - {route_result.reason}")
            
        except Exception as e:
            logger.error(f"âŒ [{context.request_id}] è·¯ç”±å†³ç­–å¤±è´¥: {e}")
            # è·¯ç”±å¤±è´¥æ—¶ä½¿ç”¨é»˜è®¤å€¼
            context.model_type = "small"
            context.metadata["route_error"] = str(e)
            context.metadata["route_reason"] = "è·¯ç”±å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹"
        
        return context
```

**LLMInvocationHandler**ï¼ˆå®é™…è°ƒç”¨LLMæœåŠ¡ï¼‰:

```python
class LLMInvocationHandler(PipelineHandler):
    """LLMè°ƒç”¨å¤„ç†å™¨"""
    
    def __init__(self, config_manager):
        super().__init__("LLMInvocationHandler")
        self._config = config_manager
    
    async def _process(self, context: ChatContext) -> ChatContext:
        """è°ƒç”¨è¿œç¨‹LLM"""
        # æ£€æŸ¥æ˜¯å¦éœ€è¦è·³è¿‡ï¼ˆçº¯å…³é”®è¯åˆ‡æ¢ï¼‰
        if context.skip_reason == "keyword_only_switch":
            return context
        
        # æ£€æŸ¥æ¨¡å‹ç±»å‹
        if not context.model_type:
            logger.warning(f"[{context.request_id}] model_typeæœªè®¾ç½®ï¼Œä½¿ç”¨é»˜è®¤smallæ¨¡å‹")
            context.model_type = "small"
        
        try:
            # åŠ¨æ€å¯¼å…¥ä»¥é¿å…å¾ªç¯ä¾èµ–
            from services.llm_service import LLMServiceFactory, ModelProvider
            from models.base import ChatCompletionRequest, Message
            
            # è·å–è™šæ‹Ÿæ¨¡å‹é…ç½®
            vm_config = self._config.get(f"ai-gateway.virtual_models.{context.virtual_model}")
            if not vm_config:
                raise ValueError(f"è™šæ‹Ÿæ¨¡å‹é…ç½®ä¸å­˜åœ¨: {context.virtual_model}")
            
            # è·å–å…·ä½“æ¨¡å‹é…ç½®
            model_config = vm_config.get(context.model_type, {})
            if not model_config:
                raise ValueError(f"æ¨¡å‹ç±»å‹é…ç½®ä¸å­˜åœ¨: {context.model_type}")
            
            # ç¡®å®šæä¾›å•†
            provider_str = model_config.get("provider", "siliconflow").lower()
            if provider_str == "openai":
                provider = ModelProvider.OPENAI
            elif provider_str == "ollama":
                provider = ModelProvider.OLLAMA
            else:
                provider = ModelProvider.SILICONFLOW
            
            # åˆ›å»ºLLMæœåŠ¡
            llm_service = LLMServiceFactory.create(
                provider=provider,
                base_url=model_config.get("base_url", "https://api.siliconflow.cn/v1"),
                api_key=model_config.get("api_key"),
                model=model_config.get("model", "Qwen/Qwen2.5-7B-Instruct"),
                temperature=context.temperature,
                max_tokens=context.max_tokens
            )
            
            # æ„å»ºè¯·æ±‚
            chat_request = ChatCompletionRequest(
                model=model_config.get("model", "unknown"),
                messages=[
                    Message(role=msg.get("role", "user"), content=msg.get("content", ""))
                    for msg in context.messages
                ],
                stream=False,
                temperature=context.temperature,
                max_tokens=context.max_tokens
            )
            
            # è°ƒç”¨LLM
            response = await llm_service.chat(chat_request)
            
            # æå–å“åº”å†…å®¹
            if response.choices:
                context.response_content = response.choices[0].message.content
            
            # è®°å½•tokenä½¿ç”¨
            if response.usage:
                context.metadata["prompt_tokens"] = response.usage.prompt_tokens
                context.metadata["completion_tokens"] = response.usage.completion_tokens
                context.metadata["total_tokens"] = response.usage.total_tokens
            
            context.metadata["model_used"] = model_config.get("model")
            context.metadata["llm_called"] = True
            
            await llm_service.close()
            
        except ValueError as e:
            logger.error(f"[{context.request_id}] LLMé…ç½®é”™è¯¯: {e}")
            context.error_occurred = True
            context.response_content = "æŠ±æ­‰ï¼ŒAIæœåŠ¡é…ç½®é”™è¯¯ï¼Œè¯·è”ç³»ç®¡ç†å‘˜ã€‚"
            context.metadata["llm_config_error"] = str(e)
        except Exception as e:
            logger.error(f"[{context.request_id}] LLMè°ƒç”¨å¤±è´¥: {e}")
            context.error_occurred = True
            context.response_content = "æŠ±æ­‰ï¼ŒAIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚"
            context.metadata["llm_error"] = str(e)
        
        return context
```

**æ³¨æ„äº‹é¡¹**:
- å…³é”®è¯æ›¿æ¢åœ¨ Phase 3ï¼ˆæ¨¡å‹å±‚ï¼‰æœ€å…ˆæ‰§è¡Œ
- åŒ¹é…æˆåŠŸåç›´æ¥è¿”å›ï¼Œä¸è°ƒç”¨åç»­çš„ ModelRouter.route()
- æ›¿æ¢åçš„æ¶ˆæ¯ç”¨äºå‘é€ç»™LLMï¼Œä½†åŸå§‹æ¶ˆæ¯ä¿å­˜åœ¨ metadata ä¸­
- RawDataArchiveHandler ä¼šå°†åŸå§‹æ¶ˆæ¯ä¸€èµ·å½’æ¡£

**RawDataArchiveHandler**ï¼ˆæ°¸ä¹…å½’æ¡£ï¼Œè‡ªåŠ¨æ¸…ç†ï¼‰:

```python
class RawDataArchiveHandler(PipelineHandler):
    """å®Œæ•´æ•°æ®å½’æ¡£ - ç”¨äºè°ƒè¯•å’Œå®¡è®¡ï¼Œæ ¹æ®é…ç½®è‡ªåŠ¨æ¸…ç†"""
    
    def __init__(self, conversation_manager):
        super().__init__("RawDataArchiveHandler")
        self._cm = conversation_manager
        self._db = conversation_manager._db
    
    async def _process(self, context: ChatContext) -> ChatContext:
        archive_data = {
            "conversation_id": context.conversation_id,
            "request_id": context.request_id,
            "timestamp": datetime.utcnow(),
            "request": {
                "user_message": context.user_message,
                "virtual_model": context.virtual_model,
                "messages": context.messages,
                "temperature": context.temperature,
                "max_tokens": context.max_tokens,
                "knowledge_enabled": context.metadata.get("knowledge_enabled", False),
                "web_search_enabled": context.metadata.get("web_search_enabled", False)
            },
            "response": {
                "content": context.response_content,
                "model_type": context.model_type,
                "model_used": context.metadata.get("model_used"),
                "tokens_used": context.metadata.get("tokens_used")
            },
            "processing_metadata": context.metadata,
            "duration_ms": (time.time() - context.start_time) * 1000
        }
        
        # ä¿å­˜åˆ°raw_conversation_logsé›†åˆ
        await self._db["raw_conversation_logs"].insert_one(archive_data)
        
        logger.info(f"ğŸ“¦ [{context.request_id}] åŸå§‹æ•°æ®å·²å½’æ¡£")
        return context
```

#### 3.5.4 æ•°æ®æ¸…ç†ç­–ç•¥

æ ¹æ® `config.yml` ä¸­çš„ `ai-gateway.log.system.retention.days` é…ç½®è‡ªåŠ¨æ¸…ç†ï¼š

```python
# core/tasks/cleanup_task.py

from datetime import datetime, timedelta
import logging

logger = logging.getLogger(__name__)


class RawDataCleanupTask:
    """å®šæ—¶æ¸…ç†Rawæ•°æ®ä»»åŠ¡"""
    
    def __init__(self, db, config_manager):
        self._db = db
        self._config = config_manager
    
    async def cleanup(self):
        """æ‰§è¡Œæ¸…ç†"""
        retention_days = self._config.get(
            "ai-gateway.log.system.retention.days",
            default=30
        )
        
        cutoff_date = datetime.utcnow() - timedelta(days=retention_days)
        
        # åˆ é™¤è¿‡æœŸæ•°æ®
        result = await self._db["raw_conversation_logs"].delete_many({
            "timestamp": {"$lt": cutoff_date}
        })
        
        logger.info(f"ğŸ§¹ Rawæ•°æ®æ¸…ç†å®Œæˆ: åˆ é™¤ {result.deleted_count} æ¡è®°å½•ï¼ˆä¿ç•™{retention_days}å¤©ï¼‰")
        return result.deleted_count
```

#### 3.5.5 é”™è¯¯æ¢å¤æœºåˆ¶

```python
class ErrorRecoveryHandler:
    """é”™è¯¯æ¢å¤åŒ…è£…å™¨ - ç¡®ä¿æ¶ˆæ¯ä¸ä¸¢å¤±"""
    
    def __init__(self, conversation_manager):
        self._cm = conversation_manager
    
    async def handle_with_recovery(self, context: ChatContext, chain: PipelineHandler):
        """å¸¦é”™è¯¯æ¢å¤çš„å¤„ç†"""
        try:
            return await chain.handle(context)
        except Exception as e:
            logger.error(f"âŒ [{context.request_id}] èŒè´£é“¾æ‰§è¡Œå¤±è´¥: {e}")
            
            # ç¡®ä¿ç”¨æˆ·æ¶ˆæ¯å·²ä¿å­˜ï¼ˆå¦‚æœæ²¡ä¿å­˜çš„è¯ï¼‰
            if not context.user_message_saved:
                try:
                    if not context.conversation_id:
                        context.conversation_id = await self._cm.create_conversation(
                            context.virtual_model
                        )
                    
                    await self._cm.add_message(
                        context.conversation_id,
                        "user",
                        context.user_message,
                        metadata={
                            "error_occurred": True,
                            "error_message": str(e),
                            "timestamp": datetime.utcnow().isoformat()
                        }
                    )
                    logger.info(f"ğŸ’¾ [{context.request_id}] ç´§æ€¥ä¿å­˜ç”¨æˆ·æ¶ˆæ¯æˆåŠŸ")
                except Exception as save_error:
                    logger.error(f"âŒ [{context.request_id}] ç´§æ€¥ä¿å­˜å¤±è´¥: {save_error}")
            
            # è¿”å›å‹å¥½çš„é”™è¯¯å“åº”
            context.response_content = "æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‡ºç°äº†é”™è¯¯ã€‚è¯·ç¨åé‡è¯•ã€‚"
            context.error_occurred = True
            context.metadata["error"] = str(e)
            
            return context
```

#### 3.5.6 ä½¿ç”¨ç¤ºä¾‹

**ç®€åŒ–åçš„ chat.py å®ç°**ï¼ˆLLMè°ƒç”¨å·²æ•´åˆåˆ°èŒè´£é“¾ï¼‰ï¼š

```python
# api/proxy/v1/chat.py

@router.post("/chat/completions")
async def chat_completions(
    request: Request,
    model_info: dict = Depends(verify_proxy_key),
    conversation_manager: ConversationManager = Depends(get_conversation_manager),
    skill_manager: SkillManager = Depends(get_skill_manager),
    config_manager: ConfigManager = Depends(get_config_manager),
    model_router: ModelRouter = Depends(get_model_router)
):
    """
    å¯¹è¯æ¥å£ - ä½¿ç”¨èŒè´£é“¾æ¨¡å¼
    
    æµç¨‹ç®€åŒ–è¯´æ˜ï¼š
    1. LLMè°ƒç”¨å·²æ•´åˆåˆ°èŒè´£é“¾ä¸­çš„ LLMInvocationHandler
    2. æ¶ˆæ¯ä¿å­˜ç”± UserMessagePersistence å’Œ AssistantMessagePersistence è‡ªåŠ¨å®Œæˆ
    3. å‰ç«¯æ— éœ€æ‰‹åŠ¨è°ƒç”¨ä¿å­˜API
    """
    
    # 1. è§£æè¯·æ±‚
    body = await request.json()
    
    # 2. æ„å»ºä¸Šä¸‹æ–‡
    context = ChatContext(
        conversation_id=body.get("conversation_id"),
        virtual_model=model_info["name"],
        messages=body.get("messages", []),
        user_message=body.get("messages", [])[-1].get("content", "") if body.get("messages") else "",
        stream=False,
        temperature=body.get("temperature", 0.7),
        max_tokens=body.get("max_tokens", 2000),
        metadata={"client_ip": request.client.host}
    )
    
    # 3. åˆ›å»ºèŒè´£é“¾
    pipeline = ChatPipeline(
        conversation_manager=conversation_manager,
        skill_manager=skill_manager,
        config_manager=config_manager,
        model_router=model_router
    )
    
    # 4. æ‰§è¡Œå¤„ç†ï¼ˆèŒè´£é“¾å†…éƒ¨å®Œæˆï¼šéªŒè¯â†’ä¿å­˜ç”¨æˆ·æ¶ˆæ¯â†’è·¯ç”±â†’è°ƒç”¨LLMâ†’ä¿å­˜åŠ©æ‰‹å›å¤â†’å½’æ¡£ï¼‰
    result = await pipeline.process(context)
    
    # 5. è¿”å›å“åº”
    if result.error_occurred:
        return JSONResponse(
            status_code=500,
            content={
                "error": {
                    "message": result.response_content,
                    "type": "processing_error",
                    "request_id": result.request_id
                }
            }
        )
    
    # å“åº”åŒ…å« conversation_idï¼Œå‰ç«¯å¯ç”¨å®ƒæ›´æ–°å¯¹è¯åˆ—è¡¨
    return result.final_response
```

**å…³é”®æ”¹è¿›**ï¼š
- âœ… LLMInvocationHandler å®é™…è°ƒç”¨LLMæœåŠ¡ï¼Œä¸å†éœ€è¦åœ¨èŒè´£é“¾å¤–æ‰‹åŠ¨è°ƒç”¨
- âœ… è‡ªåŠ¨ä¿å­˜ç”¨æˆ·æ¶ˆæ¯å’ŒåŠ©æ‰‹å›å¤ï¼Œå‰ç«¯æ— éœ€é¢å¤–è°ƒç”¨ä¿å­˜API
- âœ… æ‰€æœ‰å®¢æˆ·ç«¯ï¼ˆWebChat/ChatBox/ç¬¬ä¸‰æ–¹ï¼‰ç»Ÿä¸€é€šè¿‡èŒè´£é“¾å¤„ç†

---

### 3.4 å¯¹è¯ç®¡ç†å™¨ (ConversationManager)

**èŒè´£**: å¯¹è¯çš„åˆ›å»ºã€æŸ¥è¯¢ã€ä¿å­˜ã€åˆ é™¤

**ç±»è®¾è®¡**:
```python
class ConversationManager:
    _mongodb: AsyncIOMotorClient
    _redis: Redis
    _config_manager: ConfigManager
    
    def __init__(self, mongodb, redis, config_manager):
        self._mongodb = mongodb
        self._redis = redis
        self._config_manager = config_manager
        self._db = mongodb[config_manager.get("storage.mongodb.database")]
        self._collection = self._db["conversations"]
    
    async def create_conversation(self, virtual_model: str) -> str:
        # åˆ›å»ºæ–°ä¼šè¯
        conversation_id = generate_uuid()
        doc = {
            "_id": conversation_id,
            "virtual_model": virtual_model,
            "messages": [],
            "created_at": datetime.utcnow(),
            "updated_at": datetime.utcnow(),
            "message_count": 0
        }
        await self._collection.insert_one(doc)
        return conversation_id
    
    async def add_message(self, conversation_id: str, 
                         role: str, 
                         content: str,
                         metadata: Optional[Dict] = None) -> bool:
        # æ·»åŠ æ¶ˆæ¯åˆ°ä¼šè¯
        message = {
            "role": role,
            "content": content,
            "timestamp": datetime.utcnow(),
            "metadata": metadata or {}
        }
        await self._collection.update_one(
            {"_id": conversation_id},
            {
                "$push": {"messages": message},
                "$set": {"updated_at": datetime.utcnow()},
                "$inc": {"message_count": 1}
            }
        )
        return True
    
    async def get_conversation(self, conversation_id: str) -> Optional[Conversation]:
        # è·å–ä¼šè¯è¯¦æƒ…
        doc = await self._collection.find_one({"_id": conversation_id})
        if doc:
            return Conversation(**doc)
        return None
    
    async def get_or_create_by_fingerprint(
        self, 
        fingerprint: str, 
        virtual_model: str,
        ttl_minutes: int = 30
    ) -> str:
        """
        é€šè¿‡æŒ‡çº¹è·å–æˆ–åˆ›å»ºå¯¹è¯ï¼ˆç”¨äºChatBoxç­‰ä¸å‘é€conversation_idçš„å®¢æˆ·ç«¯ï¼‰
        
        Args:
            fingerprint: æ¶ˆæ¯æŒ‡çº¹ï¼ˆåŸºäºå‰2æ¡ç”¨æˆ·æ¶ˆæ¯çš„MD5ï¼‰
            virtual_model: è™šæ‹Ÿæ¨¡å‹åç§°
            ttl_minutes: æŒ‡çº¹è¿‡æœŸæ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰
            
        Returns:
            str: å¯¹è¯IDï¼ˆç°æœ‰æˆ–æ–°åˆ›å»ºï¼‰
        """
        try:
            # 1. å°è¯•ä»Redisè·å–ç°æœ‰å¯¹è¯
            if self._redis:
                cache_key = f"conversation:fingerprint:{fingerprint}"
                existing_id = await self._redis.get(cache_key)
                
                if existing_id:
                    # éªŒè¯å¯¹è¯æ˜¯å¦ä»ç„¶å­˜åœ¨
                    existing_conv = await self.get_conversation(existing_id)
                    if existing_conv and existing_conv.virtual_model == virtual_model:
                        return existing_id
            
            # 2. åˆ›å»ºæ–°å¯¹è¯
            conversation_id = await self.create_conversation(virtual_model)
            
            # 3. ä¿å­˜æŒ‡çº¹åˆ°Redis
            if self._redis:
                cache_key = f"conversation:fingerprint:{fingerprint}"
                await self._redis.setex(cache_key, ttl_minutes * 60, conversation_id)
            
            return conversation_id
            
        except Exception as e:
            # å¤±è´¥æ—¶åˆ›å»ºæ–°å¯¹è¯
            return await self.create_conversation(virtual_model)
    
    async def list_conversations(self, 
                                 virtual_model: Optional[str] = None,
                                 start_time: Optional[datetime] = None,
                                 end_time: Optional[datetime] = None,
                                 keyword: Optional[str] = None,
                                 limit: int = 20,
                                 offset: int = 0) -> Tuple[List[Conversation], int]:
        # åˆ—è¡¨æŸ¥è¯¢ï¼ˆæ”¯æŒç­›é€‰ã€åˆ†é¡µï¼‰
        query = {}
        if virtual_model:
            query["virtual_model"] = virtual_model
        if start_time or end_time:
            query["updated_at"] = {}
            if start_time:
                query["updated_at"]["$gte"] = start_time
            if end_time:
                query["updated_at"]["$lte"] = end_time
        if keyword:
            query["$text"] = {"$search": keyword}  # éœ€è¦æ–‡æœ¬ç´¢å¼•
        
        cursor = self._collection.find(query).sort("updated_at", -1).skip(offset).limit(limit)
        conversations = [Conversation(**doc) async for doc in cursor]
        total = await self._collection.count_documents(query)
        return conversations, total
    
    async def delete_conversation(self, conversation_id: str) -> bool:
        # åˆ é™¤ä¼šè¯
        result = await self._collection.delete_one({"_id": conversation_id})
        return result.deleted_count > 0
```

---

### 3.5 çŸ¥è¯†åº“ç®¡ç†å™¨ (KnowledgeManager)

**èŒè´£**: æ–‡æ¡£ç®¡ç†ã€å‘é‡åŒ–ã€æ£€ç´¢

**ç±»è®¾è®¡**:
```python
class KnowledgeManager:
    _mongodb: AsyncIOMotorClient
    _qdrant: QdrantClient
    _embedding_service: EmbeddingService
    _config_manager: ConfigManager
    
    def __init__(self, mongodb, qdrant, embedding_service, config_manager):
        self._mongodb = mongodb
        self._qdrant = qdrant
        self._embedding_service = embedding_service
        self._config_manager = config_manager
        self._db = mongodb[config_manager.get("storage.mongodb.database")]
        self._docs_collection = self._db["knowledge_docs"]
    
    async def upload_document(self, 
                             file: UploadFile,
                             virtual_model: str,
                             is_shared: bool,
                             chunk_size: int = 500,
                             overlap: int = 50,
                             language: str = "zh") -> Document:
        # ä¸Šä¼ æ–‡æ¡£æµç¨‹
        # 1. ä¿å­˜æ–‡ä»¶åˆ°upload/textfile/
        # 2. æå–æ–‡æœ¬å†…å®¹
        # 3. åˆ†æ®µå¤„ç†
        # 4. å‘é‡åŒ–å¹¶å­˜å‚¨åˆ°Qdrant
        # 5. ä¿å­˜å…ƒæ•°æ®åˆ°MongoDB
        
    async def vectorize_document(self, document_id: str) -> bool:
        # é‡æ–°å‘é‡åŒ–æ–‡æ¡£
        
    async def search(self, 
                    query: str, 
                    virtual_model: Optional[str] = None,
                    threshold: float = 0.76,
                    top_k: int = 5) -> List[SearchResult]:
        # å‘é‡æ£€ç´¢
        # 1. è·å–queryçš„embedding
        # 2. åœ¨Qdrantä¸­æœç´¢
        # 3. è¿‡æ»¤threshold
        # 4. è¿”å›ç»“æœ
        
    async def extract_knowledge(self, text: str, virtual_model: str) -> List[KnowledgeChunk]:
        # æ‰§è¡ŒçŸ¥è¯†æå–Skill
        skill_result = await skill_manager.execute(
            "knowledge", "ç®€å•æå–",
            text=text,
            virtual_model=virtual_model
        )
        return skill_result.get("chunks", [])
```

---

### 3.6 åª’ä½“å¤„ç†å™¨ (MediaProcessor)

**èŒè´£**: éŸ³è§†é¢‘ä¸Šä¼ ã€è½¬å½•ã€çŸ¥è¯†æå–

**ç±»è®¾è®¡**:
```python
class MediaProcessor:
    _mongodb: AsyncIOMotorClient
    _redis: Redis
    _whisper_service: WhisperService
    _knowledge_manager: KnowledgeManager
    
    def __init__(self, mongodb, redis, whisper_service, knowledge_manager):
        self._mongodb = mongodb
        self._redis = redis
        self._whisper_service = whisper_service
        self._knowledge_manager = knowledge_manager
        self._db = mongodb["ai_gateway"]
        self._collection = self._db["media_files"]
    
    async def upload_file(self, 
                         file: UploadFile,
                         media_type: str,  # video/audio/text
                         processor: str = "whisper",
                         model: str = "base",
                         language: str = "zh",
                         auto_transcribe: bool = True) -> MediaFile:
        # ä¸Šä¼ æ–‡ä»¶
        # 1. ä¿å­˜åˆ°upload/{media_type}/
        # 2. åˆ›å»ºMongoDBè®°å½•
        # 3. å¦‚æœauto_transcribeï¼Œæäº¤è½¬å½•ä»»åŠ¡åˆ°Redisé˜Ÿåˆ—
        
    async def submit_transcription_task(self, media_id: str) -> bool:
        # æäº¤è½¬å½•ä»»åŠ¡åˆ°Redisé˜Ÿåˆ—
        await self._redis.lpush("queue:transcription", media_id)
        await self._collection.update_one(
            {"_id": media_id},
            {"$set": {"status": "pending", "updated_at": datetime.utcnow()}}
        )
        return True
    
    async def process_transcription(self, media_id: str):
        # è½¬å½•å·¥ä½œè¿›ç¨‹æ‰§è¡Œ
        # 1. è·å–åª’ä½“æ–‡ä»¶ä¿¡æ¯
        # 2. è°ƒç”¨Whisperè½¬å½•
        # 3. ä¿å­˜è½¬å½•æ–‡æœ¬
        # 4. å¦‚æœé…ç½®äº†è‡ªåŠ¨çŸ¥è¯†æå–ï¼Œè°ƒç”¨KnowledgeManager
        # 5. æ›´æ–°çŠ¶æ€ä¸ºcompleted
        
    async def download_from_url(self, 
                               url: str,
                               media_type: str,
                               **transcription_options) -> MediaFile:
        # ä»URLä¸‹è½½å¹¶å¤„ç†
```

---

### 3.7 RSSæŠ“å–å™¨ (RSSFetcher)

**èŒè´£**: RSSè®¢é˜…ç®¡ç†ã€æŠ“å–ã€å†…å®¹æå–ã€ä½¿ç”¨MongoDBå­˜å‚¨

**ç±»è®¾è®¡**:
```python
class RSSFetcher:
    _mongodb: AsyncIOMotorClient
    _http_client: httpx.AsyncClient
    _config: Dict[str, Any]
    
    def __init__(self, mongodb, config: Dict[str, Any] = None):
        self._mongodb = mongodb
        self._config = config or {}
        self._http_client = httpx.AsyncClient(timeout=30.0)
        self._db = mongodb["ai_gateway"]
        self._feeds_collection = self._db["rss_feeds"]
        self._articles_collection = self._db["rss_articles"]
    
    async def create_feed(self, feed_data: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ›å»ºRSSè®¢é˜…æº"""
        feed_doc = {
            "_id": ObjectId(),
            "name": feed_data["name"],
            "url": feed_data["url"],
            "enabled": feed_data.get("enabled", True),
            "fetch_interval": feed_data.get("fetch_interval", 30),
            "retention_days": feed_data.get("retention_days", 30),
            "default_permanent": feed_data.get("default_permanent", False),
            "last_fetch_time": None,
            "article_count": 0,
            "created_at": datetime.utcnow(),
            "updated_at": datetime.utcnow()
        }
        await self._feeds_collection.insert_one(feed_doc)
        return self._doc_to_feed(feed_doc)
    
    async def get_feeds(self, enabled: Optional[bool] = None, 
                       page: int = 1, page_size: int = 20) -> Tuple[List[Dict], int]:
        """è·å–è®¢é˜…æºåˆ—è¡¨ï¼ˆæ”¯æŒåˆ†é¡µå’Œç­›é€‰ï¼‰"""
        query = {}
        if enabled is not None:
            query["enabled"] = enabled
        
        skip = (page - 1) * page_size
        cursor = self._feeds_collection.find(query).skip(skip).limit(page_size)
        feeds = [self._doc_to_feed(doc) async for doc in cursor]
        total = await self._feeds_collection.count_documents(query)
        return feeds, total
    
    async def update_feed(self, feed_id: str, update_data: Dict[str, Any]) -> Optional[Dict]:
        """æ›´æ–°è®¢é˜…æº"""
        update_doc = {"updated_at": datetime.utcnow()}
        for key in ["name", "enabled", "fetch_interval", "retention_days", "default_permanent"]:
            if key in update_data:
                update_doc[key] = update_data[key]
        
        result = await self._feeds_collection.find_one_and_update(
            {"_id": ObjectId(feed_id)},
            {"$set": update_doc},
            return_document=True
        )
        return self._doc_to_feed(result) if result else None
    
    async def delete_feed(self, feed_id: str) -> bool:
        """åˆ é™¤è®¢é˜…æºåŠå…¶æ–‡ç« """
        # åˆ é™¤å…³è”æ–‡ç« 
        await self._articles_collection.delete_many({"feed_id": feed_id})
        # åˆ é™¤è®¢é˜…æº
        result = await self._feeds_collection.delete_one({"_id": ObjectId(feed_id)})
        return result.deleted_count > 0
    
    async def fetch_feed(self, feed_id: str) -> Dict[str, Any]:
        """ç«‹å³æŠ“å–å•ä¸ªRSSè®¢é˜…æº"""
        feed = await self._feeds_collection.find_one({"_id": ObjectId(feed_id)})
        if not feed:
            raise ValueError(f"Feed not found: {feed_id}")
        
        # è§£æRSS feed
        parsed = feedparser.parse(feed["url"])
        fetched_count = 0
        
        for entry in parsed.entries:
            # æ£€æŸ¥æ–‡ç« æ˜¯å¦å·²å­˜åœ¨
            existing = await self._articles_collection.find_one({
                "feed_id": feed_id,
                "url": entry.link
            })
            if existing:
                continue
            
            # æŠ“å–å®Œæ•´å†…å®¹
            article_content = await self._fetch_full_content(entry.link)
            
            # ä¿å­˜æ–‡ç« 
            article_doc = {
                "_id": ObjectId(),
                "feed_id": feed_id,
                "title": entry.get("title", "æ— æ ‡é¢˜"),
                "url": entry.link,
                "content": article_content["markdown"],
                "content_length": len(article_content["markdown"]),
                "published_at": self._parse_date(entry.get("published_parsed") or entry.get("updated_parsed")),
                "fetched_at": datetime.utcnow(),
                "is_read": False
            }
            await self._articles_collection.insert_one(article_doc)
            fetched_count += 1
        
        # æ›´æ–°æœ€åæŠ“å–æ—¶é—´å’Œæ–‡ç« æ•°
        await self._feeds_collection.update_one(
            {"_id": ObjectId(feed_id)},
            {"$set": {
                "last_fetch_time": datetime.utcnow(),
                "article_count": await self._articles_collection.count_documents({"feed_id": feed_id})
            }}
        )
        
        return {
            "success": True,
            "message": f"æˆåŠŸæŠ“å– {fetched_count} ç¯‡æ–‡ç« ",
            "fetch_id": str(ObjectId()),
            "feed_id": feed_id,
            "articles_fetched": fetched_count
        }
    
    async def _fetch_full_content(self, url: str) -> Dict[str, str]:
        """çˆ¬å–å®Œæ•´æ–‡ç« å†…å®¹ï¼ˆä½¿ç”¨readability + html2textï¼‰"""
        try:
            response = await self._http_client.get(url, follow_redirects=True)
            raw_html = response.text
            
            # ä½¿ç”¨readabilityæå–æ­£æ–‡
            doc = Document(raw_html)
            cleaned_html = doc.summary()
            
            # è½¬æ¢ä¸ºMarkdown
            markdown_content = html2text.html2text(cleaned_html)
            
            return {
                "markdown": markdown_content,
                "html": cleaned_html,
                "raw": raw_html[:10000],  # é™åˆ¶åŸå§‹HTMLå¤§å°
                "status": "success"
            }
        except Exception as e:
            return {
                "markdown": f"æŠ“å–å¤±è´¥: {str(e)}",
                "html": "",
                "raw": "",
                "status": "failed"
            }
    
    async def get_articles(self, feed_id: Optional[str] = None,
                          is_read: Optional[bool] = None,
                          page: int = 1, page_size: int = 20) -> Tuple[List[Dict], int]:
        """è·å–æ–‡ç« åˆ—è¡¨ï¼ˆæ”¯æŒfeed_idå’Œis_readç­›é€‰ï¼‰"""
        query = {}
        if feed_id:
            query["feed_id"] = feed_id
        if is_read is not None:
            query["is_read"] = is_read
        
        skip = (page - 1) * page_size
        cursor = self._articles_collection.find(query) \
            .sort("published_at", -1) \
            .skip(skip).limit(page_size)
        
        articles = [self._doc_to_article(doc) async for doc in cursor]
        total = await self._articles_collection.count_documents(query)
        return articles, total
    
    async def get_article(self, article_id: str) -> Optional[Dict]:
        """è·å–æ–‡ç« è¯¦æƒ…"""
        article = await self._articles_collection.find_one({"_id": ObjectId(article_id)})
        if not article:
            return None
        
        # è·å–è®¢é˜…æºåç§°
        feed = await self._feeds_collection.find_one({"_id": ObjectId(article["feed_id"])})
        article["feed_name"] = feed["name"] if feed else "æœªçŸ¥æ¥æº"
        
        return self._doc_to_article(article)
    
    async def mark_article_read(self, article_id: str, is_read: bool = True) -> Optional[Dict]:
        """æ ‡è®°æ–‡ç« å·²è¯»/æœªè¯»"""
        result = await self._articles_collection.find_one_and_update(
            {"_id": ObjectId(article_id)},
            {"$set": {"is_read": is_read}},
            return_document=True
        )
        return self._doc_to_article(result) if result else None
    
    def _doc_to_feed(self, doc: Dict) -> Dict:
        """å°†MongoDBæ–‡æ¡£è½¬æ¢ä¸ºFeedå¯¹è±¡"""
        return {
            "id": str(doc["_id"]),
            "name": doc["name"],
            "url": doc["url"],
            "enabled": doc["enabled"],
            "fetch_interval": doc["fetch_interval"],
            "retention_days": doc["retention_days"],
            "default_permanent": doc["default_permanent"],
            "last_fetch_time": doc["last_fetch_time"].isoformat() if doc.get("last_fetch_time") else None,
            "article_count": doc.get("article_count", 0),
            "created_at": doc["created_at"].isoformat() if doc.get("created_at") else None,
            "updated_at": doc["updated_at"].isoformat() if doc.get("updated_at") else None
        }
    
    def _doc_to_article(self, doc: Dict) -> Dict:
        """å°†MongoDBæ–‡æ¡£è½¬æ¢ä¸ºArticleå¯¹è±¡"""
        return {
            "id": str(doc["_id"]),
            "feed_id": doc["feed_id"],
            "feed_name": doc.get("feed_name", ""),
            "title": doc["title"],
            "url": doc["url"],
            "content": doc["content"],
            "content_length": doc.get("content_length", 0),
            "published_at": doc["published_at"].isoformat() if doc.get("published_at") else None,
            "fetched_at": doc["fetched_at"].isoformat() if doc.get("fetched_at") else None,
            "is_read": doc.get("is_read", False)
        }
```

**çƒ­é—¨è®¢é˜…æºé¢„è®¾æ•°æ®**:
```python
POPULAR_RSS_SOURCES = [
    {"name": "å°‘æ•°æ´¾", "url": "https://sspai.com/feed", "description": "é«˜å“è´¨æ•°å­—æ¶ˆè´¹æŒ‡å—", "subscriber_count": "31.5K"},
    {"name": "36æ°ª", "url": "https://36kr.com/feed", "description": "ç§‘æŠ€åˆ›æŠ•å•†ä¸šèµ„è®¯", "subscriber_count": "12.5K"},
    {"name": "é˜®ä¸€å³°çš„ç½‘ç»œæ—¥å¿—", "url": "http://www.ruanyifeng.com/blog/atom.xml", "description": "ç§‘æŠ€çˆ±å¥½è€…å‘¨åˆŠ", "subscriber_count": "8.9K"},
    {"name": "çŸ¥ä¹æ—¥æŠ¥", "url": "https://www.zhihu.com/rss", "description": "çŸ¥ä¹ç²¾é€‰å†…å®¹", "subscriber_count": "6.2K"},
    {"name": "GitHub Trending", "url": "https://github.com/trending", "description": "GitHubçƒ­é—¨é¡¹ç›®", "subscriber_count": "5.8K"},
    {"name": "InfoQ", "url": "https://www.infoq.cn/feed", "description": "ä¼ä¸šçº§æŠ€æœ¯ç¤¾åŒº", "subscriber_count": "4.5K"},
    {"name": "ç¨€åœŸæ˜é‡‘", "url": "https://juejin.cn/rss", "description": "å¼€å‘è€…æŠ€æœ¯ç¤¾åŒº", "subscriber_count": "3.2K"},
    {"name": "V2EX", "url": "https://www.v2ex.com/index.xml", "description": "åˆ›æ„å·¥ä½œè€…ç¤¾åŒº", "subscriber_count": "2.1K"},
    {"name": "æœºå™¨ä¹‹å¿ƒ", "url": "https://www.jiqizhixin.com/rss", "description": "äººå·¥æ™ºèƒ½åª’ä½“", "subscriber_count": "1.8K"},
    {"name": "çˆ±èŒƒå„¿", "url": "https://www.ifanr.com/feed", "description": "æ•°å­—å…¬æ°‘åª’ä½“", "subscriber_count": "1.5K"}
]
```

**Config.yml RSSé…ç½®**:
```yaml
rss:
  max_concurrent: 5          # æœ€å¤§å¹¶å‘æŠ“å–æ•°
  auto_fetch: true           # æ˜¯å¦è‡ªåŠ¨æŠ“å–
  fetch_interval: 30         # æŠ“å–é—´éš”ï¼ˆåˆ†é’Ÿï¼‰
  retention_days: 30         # æ–‡ç« ä¿ç•™å¤©æ•°
  default_permanent: false   # é»˜è®¤æ˜¯å¦æ°¸ä¹…ä¿å­˜
  skill:                     # RSS Skillé…ç½®
    enabled: true
    version: "v1"
    custom:
      enabled: true
      version: "v1"
```

---

## 5. æ•°æ®åº“è®¾è®¡

### 4.1 MongoDB Collections

#### conversations - å¯¹è¯é›†åˆ
```javascript
{
  "_id": "conv_uuid",
  "virtual_model": "demo1",
  "messages": [
    {
      "role": "user",
      "content": "ä½ å¥½",
      "timestamp": ISODate("2026-02-24T14:00:00Z"),
      "metadata": {}
    },
    {
      "role": "assistant", 
      "content": "ä½ å¥½ï¼",
      "timestamp": ISODate("2026-02-24T14:00:05Z"),
      "metadata": {
        "model_used": "small",
        "knowledge_references": [...],
        "routing_decision": {...}
      }
    }
  ],
  "message_count": 10,
  "created_at": ISODate("2026-02-24T14:00:00Z"),
  "updated_at": ISODate("2026-02-24T14:30:00Z"),
  "has_knowledge_reference": true
}

// ç´¢å¼•
// - { virtual_model: 1, updated_at: -1 }
// - { updated_at: -1 }
// - { has_knowledge_reference: 1 }
// - æ–‡æœ¬ç´¢å¼•: { "messages.content": "text" }
```

#### knowledge_docs - çŸ¥è¯†æ–‡æ¡£é›†åˆ
```javascript
{
  "_id": "doc_uuid",
  "filename": "è®¾è®¡æ–‡æ¡£.pdf",
  "type": "pdf",  // pdf/txt/doc/jpg
  "source": "upload",  // upload/rss/conversation
  "virtual_model": "demo1",
  "is_shared": true,
  "vectorized": true,
  "chunk_count": 5,
  "file_path": "./upload/textfile/xxx.pdf",
  "file_size": 1024000,
  "upload_time": ISODate("2026-02-24T10:00:00Z"),
  "chunks": [
    {
      "index": 0,
      "content": "ç¬¬ä¸€æ®µå†…å®¹...",
      "vector_id": "uuid_in_qdrant",
      "vectorized": true
    }
  ]
}

// ç´¢å¼•
// - { virtual_model: 1, source: 1 }
// - { vectorized: 1 }
// - { upload_time: -1 }
```

#### media_files - åª’ä½“æ–‡ä»¶é›†åˆ
```javascript
{
  "_id": "media_uuid",
  "filename": "ä¼šè®®å½•éŸ³.mp3",
  "type": "audio",  // video/audio/text
  "status": "completed",  // pending/processing/completed/failed
  "file_path": "./upload/audio/xxx.mp3",
  "file_size": 5242880,
  "transcription": {
    "processor": "whisper",
    "model": "base",
    "language": "zh",
    "text": "å®Œæ•´è½¬å½•æ–‡æœ¬...",
    "segments": [...],
    "completed_at": ISODate("2026-02-24T14:30:00Z")
  },
  "knowledge_extracted": true,
  "knowledge_doc_ids": ["doc_uuid_1", "doc_uuid_2"],
  "upload_time": ISODate("2026-02-24T14:00:00Z"),
  "updated_at": ISODate("2026-02-24T14:30:00Z")
}

// ç´¢å¼•
// - { type: 1, status: 1 }
// - { status: 1, upload_time: -1 }
```

#### rss_subscriptions - RSSè®¢é˜…é›†åˆ
```javascript
{
  "_id": "rss_uuid",
  "name": "AIæ–°é—»",
  "url": "https://news.ai.com/feed.xml",
  "enabled": true,
  "fetch_interval": 30,  // åˆ†é’Ÿ
  "retention_days": 30,
  "default_permanent": false,
  "virtual_model": "demo1",
  "article_count": 150,
  "last_fetch_time": ISODate("2026-02-24T14:00:00Z"),
  "created_at": ISODate("2026-01-01T00:00:00Z")
}
```

#### rss_articles - RSSæ–‡ç« é›†åˆ
```javascript
{
  "_id": "article_uuid",
  "subscription_id": "rss_uuid",
  "title": "AIæœ€æ–°è¿›å±•",
  "url": "https://news.ai.com/article/1",
  "content": "å®Œæ•´çš„æ–‡ç« å†…å®¹...",
  "raw_content": "åŸå§‹HTML...",
  "content_format": "markdown",
  "published_at": ISODate("2026-02-24T10:00:00Z"),
  "fetched_at": ISODate("2026-02-24T14:00:00Z"),
  "is_read": false,
  "knowledge_extracted": true,
  "knowledge_doc_ids": [...],
  "fetch_status": "full_content",  // full_content/summary_only/failed
  "fetch_method": "readability"
}

// ç´¢å¼•
// - { subscription_id: 1, fetched_at: -1 }
// - { is_read: 1 }
```

#### operation_logs - æ“ä½œæ—¥å¿—é›†åˆ
```javascript
{
  "_id": "log_uuid",
  "timestamp": ISODate("2026-02-24T14:30:00Z"),
  "type": "config",  // config/skill/model/media/rss
  "action": "æ›´æ–°è™šæ‹Ÿæ¨¡å‹é…ç½®",
  "details": {
    "model_name": "demo1",
    "changes": [...]
  },
  "status": "success",  // success/failed
  "operator": "admin",
  "ip_address": "127.0.0.1",
  "user_agent": "..."
}

// ç´¢å¼•
// - { timestamp: -1 }
// - { type: 1, timestamp: -1 }
// - { status: 1 }
```

### 4.2 Qdrant Collection

**Collectionåç§°**: `knowledge_base`

**å‘é‡é…ç½®**:
- å‘é‡ç»´åº¦: 1024 (BAAI/bge-m3)
- è·ç¦»åº¦é‡: Cosine

**Payloadå­—æ®µ**:
```javascript
{
  "document_id": "doc_uuid",
  "chunk_index": 0,
  "virtual_model": "demo1",
  "is_shared": true,
  "source": "upload",
  "created_at": "2026-02-24T10:00:00Z",
  "text_preview": "å†…å®¹å‰100å­—..."
}
```

**ç´¢å¼•**:
- `virtual_model` - keywordç´¢å¼•
- `is_shared` - boolç´¢å¼•
- `source` - keywordç´¢å¼•

### 4.3 Redis Keys

```
# é…ç½®ç¼“å­˜
config:hash                    # config.ymlçš„hashç¼“å­˜

# è™šæ‹Ÿæ¨¡å‹
virtual_model:{name}:current   # å½“å‰æ¨¡å‹ï¼ˆsmall/bigï¼‰
virtual_model:{name}:force     # æ˜¯å¦å¼ºåˆ¶

# ä¼šè¯
conversation:{id}:messages     # æ´»è·ƒä¼šè¯æ¶ˆæ¯ç¼“å­˜ï¼ˆTTL: 1å°æ—¶ï¼‰

# ä»»åŠ¡é˜Ÿåˆ—
queue:transcription            # è½¬å½•ä»»åŠ¡é˜Ÿåˆ—
queue:knowledge_extraction     # çŸ¥è¯†æå–ä»»åŠ¡é˜Ÿåˆ—
queue:rss_fetch                # RSSæŠ“å–ä»»åŠ¡é˜Ÿåˆ—

# Skillæ‰§è¡Œç¼“å­˜ï¼ˆé˜²æ­¢é‡å¤æ‰§è¡Œï¼‰
skill:execution:{log_id}       # Skillæ‰§è¡Œç»“æœç¼“å­˜

# é€Ÿç‡é™åˆ¶ï¼ˆé¢„ç•™ï¼‰
rate_limit:proxy_key:{key}     # proxy_keyè¯·æ±‚è®¡æ•°
```

---

## 6. APIå®ç°è§„åˆ’

### 5.1 è·¯ç”±æ³¨å†Œ (main.py)

```python
from fastapi import FastAPI
from api.proxy.v1 import chat, models, embeddings
from api.admin.v1 import (
    dashboard, config, models as admin_models,
    skills, conversations, knowledge, media, rss, logs, raw_data
)

app = FastAPI(title="AI Gateway", version="1.0.0")

# è™šæ‹ŸAIä»£ç†API
app.include_router(chat.router, prefix="/proxy/ai/v1", tags=["proxy"])
app.include_router(models.router, prefix="/proxy/ai/v1", tags=["proxy"])
app.include_router(embeddings.router, prefix="/proxy/ai/v1", tags=["proxy"])

# åå°ç®¡ç†API
app.include_router(dashboard.router, prefix="/admin/ai/v1", tags=["admin"])
app.include_router(config.router, prefix="/admin/ai/v1", tags=["admin"])
app.include_router(admin_models.router, prefix="/admin/ai/v1", tags=["admin"])
app.include_router(skills.router, prefix="/admin/ai/v1", tags=["admin"])
app.include_router(conversations.router, prefix="/admin/ai/v1", tags=["admin"])
app.include_router(knowledge.router, prefix="/admin/ai/v1", tags=["admin"])
app.include_router(media.router, prefix="/admin/ai/v1", tags=["admin"])
app.include_router(rss.router, prefix="/admin/ai/v1", tags=["admin"])
app.include_router(logs.router, prefix="/admin/ai/v1", tags=["admin"])
app.include_router(raw_data.router, prefix="/admin/ai/v1", tags=["admin"])
```

### 5.2 ä¾èµ–æ³¨å…¥ (dependencies.py)

```python
from fastapi import Request

# æ•°æ®åº“è¿æ¥ä¾èµ–
async def get_mongodb():
    # è¿”å›MongoDBè¿æ¥
    
async def get_redis():
    # è¿”å›Redisè¿æ¥
    
async def get_qdrant():
    # è¿”å›Qdrantè¿æ¥

# ç®¡ç†å™¨ä¾èµ–
async def get_config_manager():
    # è¿”å›ConfigManagerå•ä¾‹
    
async def get_skill_manager(config_manager=Depends(get_config_manager)):
    # è¿”å›SkillManagerå•ä¾‹
    
async def get_conversation_manager(mongodb=Depends(get_mongodb)):
    # è¿”å›ConversationManager

# ä»£ç†è®¤è¯ä¾èµ–ï¼ˆä»…ç”¨äº/proxy/ai/*ï¼‰
async def verify_proxy_key(request: Request):
    # ä»Authorizationå¤´æå–proxy_key
    # éªŒè¯æ˜¯å¦å­˜åœ¨äºconfig.ymlä¸­
    # è¿”å›virtual_modelé…ç½®
```

### 5.3 å…³é”®APIå®ç°ç¤ºä¾‹

**POST /proxy/ai/v1/chat/completions**:
```python
@router.post("/chat/completions")
async def chat_completions(
    request: ChatRequest,
    virtual_model_config: dict = Depends(verify_proxy_key),
    conversation_manager: ConversationManager = Depends(get_conversation_manager),
    model_router: ModelRouter = Depends(get_model_router),
    llm_service: LLMService = Depends(get_llm_service)
):
    # 1. è·å–æˆ–åˆ›å»ºä¼šè¯
    conversation_id = extract_conversation_id(request.messages)
    if not conversation_id:
        conversation_id = await conversation_manager.create_conversation(
            virtual_model_config["name"]
        )
    
    # 2. ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
    await conversation_manager.add_message(
        conversation_id, 
        "user", 
        request.messages[-1].content
    )
    
    # 3. æ¨¡å‹è·¯ç”±å†³ç­–
    route_result = await model_router.route(
        virtual_model_config["name"],
        request.messages[-1].content,
        conversation_id
    )
    
    # 4. çŸ¥è¯†åº“æ£€ç´¢ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    knowledge_chunks = []
    if virtual_model_config.get("knowledge", {}).get("enabled"):
        knowledge_chunks = await search_knowledge(
            request.messages[-1].content,
            virtual_model_config["name"]
        )
    
    # 5. æ„å»ºå¢å¼ºçš„prompt
    enhanced_messages = build_messages_with_context(
        request.messages,
        knowledge_chunks
    )
    
    # 6. é€‰æ‹©å®é™…æ¨¡å‹é…ç½®
    target_model = virtual_model_config[route_result.model_type]
    
    # 7. è°ƒç”¨LLMï¼ˆæµå¼æˆ–éæµå¼ï¼‰
    if request.stream:
        return StreamingResponse(
            stream_chat_response(
                target_model,
                enhanced_messages,
                conversation_id,
                conversation_manager
            ),
            media_type="text/event-stream"
        )
    else:
        response = await llm_service.chat(
            target_model,
            enhanced_messages
        )
        
        # ä¿å­˜AIå›å¤
        await conversation_manager.add_message(
            conversation_id,
            "assistant",
            response.content,
            metadata={
                "model_used": route_result.model_type,
                "routing_reason": route_result.reason
            }
        )
        
        return response
```

---

## 7. å…³é”®æµç¨‹è®¾è®¡

### 6.1 å¯¹è¯æµç¨‹

```
1. å®¢æˆ·ç«¯å‘é€ POST /proxy/ai/v1/chat/completions
   - Header: Authorization: Bearer {proxy_key}
   - Body: {model, messages, stream, ...}

2. ä¸­é—´ä»¶éªŒè¯proxy_key
   - ä»config.ymlæŸ¥æ‰¾å¯¹åº”çš„è™šæ‹Ÿæ¨¡å‹é…ç½®
   - å¦‚æœæ‰¾ä¸åˆ°ï¼Œè¿”å›401é”™è¯¯

3. åˆ›å»ºæˆ–è·å–ä¼šè¯
   - å¦‚æœæ˜¯æ–°ä¼šè¯ï¼Œåˆ›å»ºconversation_id
   - ä¿å­˜ç”¨æˆ·æ¶ˆæ¯åˆ°MongoDB

4. æ¨¡å‹è·¯ç”±å†³ç­–
   a. æ£€æŸ¥æ˜¯å¦å¼ºåˆ¶æ¨¡å¼
   b. å°è¯•å…³é”®è¯è·¯ç”±
   c. å°è¯•æ„å›¾è¯†åˆ«è·¯ç”±
   d. ä½¿ç”¨é»˜è®¤æ¨¡å‹

5. çŸ¥è¯†åº“æ£€ç´¢ï¼ˆå¦‚æœå¯ç”¨ï¼‰
   - å°†ç”¨æˆ·æŸ¥è¯¢embedding
   - åœ¨Qdrantä¸­æœç´¢ç›¸ä¼¼å‘é‡
   - è¿”å›ç›¸å…³çŸ¥è¯†ç‰‡æ®µ

6. æ„å»ºå¢å¼ºprompt
   - ç³»ç»Ÿæç¤º + çŸ¥è¯†ç‰‡æ®µ + å†å²æ¶ˆæ¯ + ç”¨æˆ·è¾“å…¥

7. è°ƒç”¨å®é™…LLM API
   - æ ¹æ®è·¯ç”±ç»“æœé€‰æ‹©small/bigæ¨¡å‹é…ç½®
   - è°ƒç”¨SiliconFlow/OpenAI/Ollama

8. æµå¼å“åº”ï¼ˆå¦‚æœstream=trueï¼‰
   - ä½¿ç”¨SSEé€å­—è¿”å›
   - ä¿å­˜å®Œæ•´å›å¤åˆ°MongoDB

9. è®°å½•æ—¥å¿—
   - è®°å½•åˆ°operation_logs
   - è®°å½•åˆ°skill execution logs
```

### 6.2 Skillæ‰§è¡Œæµç¨‹

```
1. è°ƒç”¨ skill_manager.execute(category, name, **kwargs)

2. æŸ¥æ‰¾Skill
   - æ ¹æ®config.ymlå†³å®šä½¿ç”¨systemè¿˜æ˜¯customç‰ˆæœ¬
   - åŠ è½½Skillå…ƒæ•°æ®

3. éªŒè¯è¾“å…¥
   - ä½¿ç”¨JSON SchemaéªŒè¯kwargs
   - å¦‚æœä¸é€šè¿‡ï¼Œè¿”å›ValidationError

4. æ‰§è¡ŒSkill
   a. å¦‚æœæ˜¯rule-based:
      - ç›´æ¥æ‰§è¡Œè§„åˆ™é€»è¾‘
   b. å¦‚æœæ˜¯llm-based:
      - æ„å»ºprompt
      - è°ƒç”¨LLM
      - è§£æTool Callç»“æœ

5. éªŒè¯è¾“å‡º
   - ä½¿ç”¨JSON SchemaéªŒè¯result

6. è®°å½•æ‰§è¡Œæ—¥å¿—
   - è®°å½•è¾“å…¥ã€è¾“å‡ºã€è€—æ—¶ã€çŠ¶æ€
   - ä¿å­˜åˆ°MongoDBå’Œæ–‡ä»¶

7. è¿”å›ç»“æœ
```

### 6.3 é…ç½®çƒ­é‡è½½æµç¨‹

```
1. ç”¨æˆ·è°ƒç”¨ POST /admin/ai/v1/config/reload
   æˆ– Watchdogæ£€æµ‹åˆ°config.ymlå˜åŒ–

2. è¯»å–config.ymlæ–‡ä»¶

3. éªŒè¯é…ç½®
   - ä½¿ç”¨Pydanticæ¨¡å‹éªŒè¯ç»“æ„
   - æ£€æŸ¥å¿…å¡«å­—æ®µ
   - æ£€æŸ¥æ ¼å¼æ­£ç¡®æ€§

4. å¦‚æœéªŒè¯å¤±è´¥
   - è®°å½•é”™è¯¯æ—¥å¿—
   - è¿”å›é”™è¯¯å“åº”
   - ä¿æŒæ—§é…ç½®è¿è¡Œ

5. å¦‚æœéªŒè¯é€šè¿‡
   - æ›´æ–°ConfigManagerå†…éƒ¨ç¼“å­˜
   - é€šçŸ¥æ‰€æœ‰ä¾èµ–ç»„ä»¶
   - è®°å½•æ“ä½œæ—¥å¿—

6. ç»„ä»¶æ”¶åˆ°é€šçŸ¥å
   - SkillManager: é‡è½½å—å½±å“çš„Skill
   - ModelRouter: æ›´æ–°è·¯ç”±è§„åˆ™
   - å…¶ä»–ç»„ä»¶: åˆ·æ–°é…ç½®å¼•ç”¨
```

---

## 8. é”™è¯¯å¤„ç†

### 7.1 å¼‚å¸¸ç±»å®šä¹‰

```python
# core/exceptions.py

class AIGatewayException(Exception):
    """åŸºç¡€å¼‚å¸¸"""
    status_code = 500
    error_code = "internal_error"
    
class ProxyKeyInvalid(AIGatewayException):
    """proxy_keyæ— æ•ˆ"""
    status_code = 401
    error_code = "authentication_error"
    
class VirtualModelNotFound(AIGatewayException):
    """è™šæ‹Ÿæ¨¡å‹ä¸å­˜åœ¨"""
    status_code = 404
    error_code = "model_not_found"
    
class SkillNotFound(AIGatewayException):
    """Skillä¸å­˜åœ¨"""
    status_code = 404
    error_code = "skill_not_found"
    
class SkillValidationError(AIGatewayException):
    """SkilléªŒè¯å¤±è´¥"""
    status_code = 400
    error_code = "skill_validation_error"
    
class ConfigValidationError(AIGatewayException):
    """é…ç½®éªŒè¯å¤±è´¥"""
    status_code = 400
    error_code = "config_validation_error"
    
class LLMServiceError(AIGatewayException):
    """LLMæœåŠ¡è°ƒç”¨å¤±è´¥"""
    status_code = 502
    error_code = "llm_service_error"
```

### 7.2 å…¨å±€å¼‚å¸¸å¤„ç†å™¨

```python
@app.exception_handler(AIGatewayException)
async def ai_gateway_exception_handler(request, exc):
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error": {
                "code": exc.error_code,
                "message": str(exc),
                "details": getattr(exc, "details", None)
            }
        }
    )
```

---

## 9. æ—¥å¿—è®¾è®¡

### 8.1 æ—¥å¿—åˆ†ç±»

| æ—¥å¿—ç±»å‹ | å­˜å‚¨ä½ç½® | å†…å®¹ | ä¿ç•™ç­–ç•¥ |
|----------|----------|------|----------|
| **ç³»ç»Ÿæ—¥å¿—** | ./logs/skill/system.log | SkillåŠ è½½ã€æ‰§è¡Œã€é”™è¯¯ | è½®è½¬ï¼Œ5ä¸ªå¤‡ä»½ |
| **æ‰§è¡Œæ—¥å¿—** | ./logs/skill/execution_YYYYMMDD.log | è¯¦ç»†JSONæ‰§è¡Œè®°å½• | 30å¤© |
| **æ“ä½œæ—¥å¿—** | MongoDB | é…ç½®å˜æ›´ã€Skillæ›´æ–° | 30å¤© |

### 8.2 æ—¥å¿—æ ¼å¼

**ç³»ç»Ÿæ—¥å¿—** (ç»“æ„åŒ–):
```
2026-02-24 14:30:00 [INFO] skill.manager: SkillåŠ è½½æˆåŠŸ: router/æ„å›¾è¯†åˆ«@v1
2026-02-24 14:30:05 [ERROR] skill.executor: Skillæ‰§è¡Œå¤±è´¥: router/æ„å›¾è¯†åˆ« - Connection timeout
```

**æ‰§è¡Œæ—¥å¿—** (JSON Lines):
```json
{"timestamp":"2026-02-24T14:30:00Z","skill_category":"router","skill_name":"æ„å›¾è¯†åˆ«","duration_ms":120,"status":"success"}
```

---

## 10. æµ‹è¯•ç­–ç•¥ï¼ˆTDD + 100%è¦†ç›–ç‡ï¼‰

### 10.1 æµ‹è¯•é©±åŠ¨å¼€å‘ï¼ˆTDDï¼‰æµç¨‹

**å¿…é¡»ä¸¥æ ¼éµå¾ªTDDçº¢ç»¿é‡æ„å¾ªç¯ï¼š**

```
1. ç¼–å†™æµ‹è¯•æ¡ˆä¾‹ï¼ˆJSONæ–‡ä»¶ï¼‰ â†’ 2. è¿è¡Œæµ‹è¯•ï¼ˆå¤±è´¥/çº¢è‰²ï¼‰ â†’ 3. ç¼–å†™æœ€å°å®ç° â†’ 4. è¿è¡Œæµ‹è¯•ï¼ˆé€šè¿‡/ç»¿è‰²ï¼‰ â†’ 5. é‡æ„ä¼˜åŒ–
```

**å¼€å‘æµç¨‹ï¼š**
1. **éœ€æ±‚åˆ†æ** - ç†è§£åŠŸèƒ½éœ€æ±‚
2. **ç¼–å†™æµ‹è¯•æ¡ˆä¾‹** - å°†æµ‹è¯•æ¡ˆä¾‹ä¿å­˜åˆ°JSONæ–‡ä»¶
3. **ç”Ÿæˆæµ‹è¯•ä»£ç ** - æ ¹æ®JSONç”Ÿæˆpytestæµ‹è¯•å‡½æ•°
4. **è¿è¡Œæµ‹è¯•** - ç¡®ä¿æµ‹è¯•å¤±è´¥ï¼ˆçº¢è‰²ï¼‰
5. **ç¼–å†™å®ç°** - ç¼–å†™æœ€å°ä»£ç ä½¿æµ‹è¯•é€šè¿‡
6. **è¿è¡Œæµ‹è¯•** - ç¡®ä¿æµ‹è¯•é€šè¿‡ï¼ˆç»¿è‰²ï¼‰
7. **é‡æ„ä¼˜åŒ–** - ä¼˜åŒ–ä»£ç ç»“æ„å’Œè´¨é‡
8. **è¦†ç›–ç‡æ£€æŸ¥** - ç¡®ä¿100%è¦†ç›–

### 10.2 æµ‹è¯•æ¡ˆä¾‹JSONæ ¼å¼

**æ–‡ä»¶ä½ç½®**: `test/backend/cases/{æ¨¡å—}/{åŠŸèƒ½}.test.json`

**JSON Schema:**
```json
{
  "test_suite": "skill_manager",
  "description": "Skillç®¡ç†å™¨æµ‹è¯•å¥—ä»¶",
  "author": "developer",
  "created_at": "2026-02-24",
  "test_cases": [
    {
      "id": "TC001",
      "name": "test_load_valid_skill",
      "description": "æµ‹è¯•åŠ è½½æœ‰æ•ˆçš„Skillæ–‡ä»¶",
      "category": "unit",
      "priority": "P0",
      "tags": ["skill", "loading", "positive"],
      "preconditions": [
        "Skillæ–‡ä»¶å­˜åœ¨äº skill/system/router/v1/å…³é”®è¯è·¯ç”±/SKILL.md"
      ],
      "inputs": {
        "category": "router",
        "name": "å…³é”®è¯è·¯ç”±",
        "version": "v1",
        "is_custom": false
      },
      "expected": {
        "success": true,
        "skill_name": "å…³é”®è¯è·¯ç”±",
        "skill_type": "rule-based",
        "has_py_file": false
      },
      "assertions": [
        "assert result.metadata.name == 'å…³é”®è¯è·¯ç”±'",
        "assert result.metadata.type == 'rule-based'",
        "assert result.file_path is not None"
      ]
    },
    {
      "id": "TC002",
      "name": "test_load_invalid_skill_missing_required_field",
      "description": "æµ‹è¯•åŠ è½½ç¼ºå°‘å¿…å¡«å­—æ®µçš„Skill",
      "category": "unit",
      "priority": "P0",
      "tags": ["skill", "loading", "negative", "validation"],
      "preconditions": [
        "åˆ›å»ºä¸€ä¸ªä¸´æ—¶æ— æ•ˆçš„SKILL.mdæ–‡ä»¶"
      ],
      "inputs": {
        "category": "router",
        "name": "æ— æ•ˆSkill",
        "skill_content": "---\nname: æ— æ•ˆ\n# ç¼ºå°‘descriptionå’Œtypeå­—æ®µ\n---"
      },
      "expected": {
        "success": false,
        "error_type": "SkillValidationError",
        "error_message_contains": "description"
      },
      "assertions": [
        "assert not result.success",
        "assert 'description' in result.error_message"
      ]
    },
    {
      "id": "TC003",
      "name": "test_execute_skill_with_valid_input",
      "description": "æµ‹è¯•ä½¿ç”¨æœ‰æ•ˆè¾“å…¥æ‰§è¡ŒSkill",
      "category": "unit",
      "priority": "P0",
      "tags": ["skill", "execution", "positive"],
      "preconditions": [
        "Skillå·²æˆåŠŸåŠ è½½"
      ],
      "inputs": {
        "category": "router",
        "name": "å…³é”®è¯è·¯ç”±",
        "input_params": {
          "user_input": "è¯·å†™ä¸€æ®µPythonä»£ç "
        }
      },
      "expected": {
        "success": true,
        "output": {
          "target": "big",
          "matched_rule": "ä»£ç ",
          "reason": "å…³é”®è¯åŒ¹é…: ä»£ç "
        }
      },
      "assertions": [
        "assert result.model_type == 'big'",
        "assert 'ä»£ç ' in result.reason"
      ]
    },
    {
      "id": "TC004",
      "name": "test_execute_skill_with_invalid_input_schema",
      "description": "æµ‹è¯•ä½¿ç”¨ä¸ç¬¦åˆschemaçš„è¾“å…¥æ‰§è¡ŒSkill",
      "category": "unit",
      "priority": "P1",
      "tags": ["skill", "execution", "negative", "validation"],
      "preconditions": [
        "Skillå·²æˆåŠŸåŠ è½½"
      ],
      "inputs": {
        "category": "knowledge",
        "name": "ç®€å•æå–",
        "input_params": {
          "text": "çŸ­æ–‡æœ¬"  # ç¼ºå°‘å¿…å¡«å­—æ®µ
        }
      },
      "expected": {
        "success": false,
        "error_type": "SkillValidationError",
        "error_message_contains": "required"
      },
      "assertions": [
        "assert not result.success",
        "assert result.input_valid == false"
      ]
    },
    {
      "id": "TC005",
      "name": "test_skill_execution_performance",
      "description": "æµ‹è¯•Skillæ‰§è¡Œæ€§èƒ½ï¼ˆè¾¹ç•Œæµ‹è¯•ï¼‰",
      "category": "performance",
      "priority": "P1",
      "tags": ["skill", "performance", "boundary"],
      "preconditions": [
        "Skillå·²åŠ è½½"
      ],
      "inputs": {
        "category": "knowledge",
        "name": "ç®€å•æå–",
        "input_params": {
          "text": "a" * 100000  # 10ä¸‡å­—é•¿æ–‡æœ¬ï¼ˆè¾¹ç•Œæµ‹è¯•ï¼‰
        }
      },
      "expected": {
        "success": true,
        "max_duration_ms": 5000
      },
      "assertions": [
        "assert result.duration_ms <= 5000",
        "assert len(result.chunks) > 0"
      ]
    },
    {
      "id": "TC006",
      "name": "test_concurrent_skill_execution",
      "description": "æµ‹è¯•å¹¶å‘æ‰§è¡ŒSkillï¼ˆå‹åŠ›æµ‹è¯•ï¼‰",
      "category": "performance",
      "priority": "P2",
      "tags": ["skill", "concurrency", "stress"],
      "preconditions": [
        "Skillå·²åŠ è½½"
      ],
      "inputs": {
        "concurrent_requests": 100,
        "input_params": {
          "user_input": "æµ‹è¯•è¾“å…¥"
        }
      },
      "expected": {
        "success_rate": 1.0,
        "max_duration_ms": 10000
      },
      "assertions": [
        "assert success_rate == 1.0",
        "assert avg_duration_ms <= 100"
      ]
    }
  ]
}
```

### 10.3 æµ‹è¯•æ¡ˆä¾‹ç®¡ç†è„šæœ¬

**æ–‡ä»¶**: `test/backend/generate_tests.py`

```python
#!/usr/bin/env python3
"""
æµ‹è¯•ä»£ç ç”Ÿæˆå™¨
æ ¹æ®JSONæµ‹è¯•æ¡ˆä¾‹ç”Ÿæˆpytestæµ‹è¯•ä»£ç 
"""

import json
import os
from pathlib import Path
from jinja2 import Template

TEST_TEMPLATE = '''
# Auto-generated from {{ json_file }}
# Generated at: {{ generated_at }}

import pytest
import asyncio
from datetime import datetime
{% for import_stmt in imports %}
{{ import_stmt }}
{% endfor %}

{% for case in test_cases %}
@pytest.mark.{{ case.category }}
@pytest.mark.priority("{{ case.priority }}")
{% for tag in case.tags %}
@pytest.mark.{{ tag }}
{% endfor %}
async def {{ case.name }}():
    """
    {{ case.description }}
    
    Test Case ID: {{ case.id }}
    Preconditions:
    {% for pre in case.preconditions %}
    - {{ pre }}
    {% endfor %}
    """
    # Arrange
    {% for key, value in case.inputs.items() %}
    {{ key }} = {{ value | repr }}
    {% endfor %}
    
    # Act
    {% if 'expected' in case and 'error_type' in case.expected %}
    with pytest.raises({{ case.expected.error_type }}):
        result = await {{ test_suite }}({{ case.inputs.keys() | join(', ') }})
    {% else %}
    result = await {{ test_suite }}({{ case.inputs.keys() | join(', ') }})
    {% endif %}
    
    # Assert
    {% for assertion in case.assertions %}
    {{ assertion }}
    {% endfor %}
{% endfor %}
'''

def generate_test_file(json_path: str, output_path: str):
    """æ ¹æ®JSONç”Ÿæˆæµ‹è¯•æ–‡ä»¶"""
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    template = Template(TEST_TEMPLATE)
    content = template.render(
        json_file=json_path,
        generated_at=datetime.now().isoformat(),
        test_suite=data['test_suite'],
        test_cases=data['test_cases'],
        imports=data.get('imports', [])
    )
    
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(content)
    
    print(f"Generated: {output_path}")

if __name__ == "__main__":
    # éå†æ‰€æœ‰JSONæµ‹è¯•æ¡ˆä¾‹
    cases_dir = Path(__file__).parent / "cases"
    output_dir = Path(__file__).parent / "generated"
    output_dir.mkdir(exist_ok=True)
    
    for json_file in cases_dir.rglob("*.test.json"):
        relative_path = json_file.relative_to(cases_dir)
        output_file = output_dir / relative_path.with_suffix(".py")
        output_file.parent.mkdir(parents=True, exist_ok=True)
        
        generate_test_file(str(json_file), str(output_file))
```

### 10.4 æµ‹è¯•ç±»å‹çŸ©é˜µ

| æµ‹è¯•ç±»å‹ | ç›®æ ‡è¦†ç›–ç‡ | æµ‹è¯•é‡ç‚¹ | æ–‡ä»¶å‘½å |
|---------|-----------|---------|---------|
| **å•å…ƒæµ‹è¯•** | 100% | å‡½æ•°/ç±»çº§åˆ«ï¼Œè¾¹ç•Œæ¡ä»¶ | `test_{module}.py` |
| **é›†æˆæµ‹è¯•** | 90% | APIç«¯ç‚¹ï¼Œæ•°æ®åº“äº¤äº’ | `test_integration_{feature}.py` |
| **è¾¹ç•Œæµ‹è¯•** | 100% | ç©ºå€¼ã€æå€¼ã€è¶Šç•Œã€é•¿æ–‡æœ¬ | åœ¨JSONä¸­æ ‡è®°`boundary`æ ‡ç­¾ |
| **å¼‚å¸¸æµ‹è¯•** | 100% | é”™è¯¯å¤„ç†ï¼Œå¼‚å¸¸è·¯å¾„ | åœ¨JSONä¸­æ ‡è®°`negative`æ ‡ç­¾ |
| **æ€§èƒ½æµ‹è¯•** | å…³é”®è·¯å¾„ | å“åº”æ—¶é—´ï¼Œå¹¶å‘å¤„ç† | `test_performance_{feature}.py` |
| **å®Œæ•´åº¦æµ‹è¯•** | 100% | æ‰€æœ‰åˆ†æ”¯ï¼Œæ‰€æœ‰ä»£ç è·¯å¾„ | é€šè¿‡coverageå·¥å…·éªŒè¯ |

### 10.5 è¾¹ç•Œæµ‹è¯•æ¡ˆä¾‹ï¼ˆç¤ºä¾‹ï¼‰

**æ–‡ä»¶**: `test/backend/cases/config_manager/boundary.test.json`

```json
{
  "test_suite": "config_manager",
  "test_cases": [
    {
      "id": "B001",
      "name": "test_config_with_empty_yaml",
      "description": "æµ‹è¯•ç©ºYAMLæ–‡ä»¶",
      "category": "boundary",
      "inputs": {"config_content": ""},
      "expected": {"success": false, "error_type": "ConfigValidationError"}
    },
    {
      "id": "B002",
      "name": "test_config_with_very_long_key",
      "description": "æµ‹è¯•è¶…é•¿é…ç½®é”®åï¼ˆ1000å­—ç¬¦ï¼‰",
      "category": "boundary",
      "inputs": {"key": "a" * 1000, "value": "test"},
      "expected": {"success": false}
    },
    {
      "id": "B003",
      "name": "test_config_with_special_characters",
      "description": "æµ‹è¯•åŒ…å«ç‰¹æ®Šå­—ç¬¦çš„é…ç½®å€¼",
      "category": "boundary",
      "inputs": {"key": "test", "value": "<script>alert('xss')</script>"},
      "expected": {"success": true, "value": "<script>alert('xss')</script>"}
    },
    {
      "id": "B004",
      "name": "test_config_with_unicode",
      "description": "æµ‹è¯•Unicodeå­—ç¬¦ï¼ˆä¸­æ–‡ã€emojiï¼‰",
      "category": "boundary",
      "inputs": {"key": "æµ‹è¯•", "value": "Hello ğŸ‘‹ ä¸–ç•Œ"},
      "expected": {"success": true}
    },
    {
      "id": "B005",
      "name": "test_config_with_nested_deep_structure",
      "description": "æµ‹è¯•æ·±å±‚åµŒå¥—ç»“æ„ï¼ˆ20å±‚ï¼‰",
      "category": "boundary",
      "inputs": {"depth": 20},
      "expected": {"success": true}
    },
    {
      "id": "B006",
      "name": "test_config_file_size_limit",
      "description": "æµ‹è¯•è¶…å¤§é…ç½®æ–‡ä»¶ï¼ˆ10MBï¼‰",
      "category": "boundary",
      "inputs": {"file_size_mb": 10},
      "expected": {"success": true}
    }
  ]
}
```

### 10.6 ä»£ç è´¨é‡ä¸å¤æ‚åº¦æµ‹è¯•

**å·¥å…·é…ç½®**: `pyproject.toml`

```toml
[tool.pytest.ini_options]
testpaths = ["test/backend"]
python_files = ["test_*.py", "*_test.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]
addopts = [
    "-v",
    "--tb=short",
    "--strict-markers",
    "--cov=backend",
    "--cov-report=term-missing",
    "--cov-report=html:reports/coverage",
    "--cov-report=xml:reports/coverage.xml",
    "--cov-fail-under=100",  # 100%è¦†ç›–ç‡è¦æ±‚
]
markers = [
    "unit: Unit tests",
    "integration: Integration tests",
    "performance: Performance tests",
    "boundary: Boundary tests",
    "P0: Priority 0 (critical)",
    "P1: Priority 1 (high)",
    "P2: Priority 2 (medium)",
]

[tool.coverage.run]
source = ["backend"]
omit = [
    "*/tests/*",
    "*/test/*",
    "backend/main.py",  # å…¥å£æ–‡ä»¶å¯ä»¥æ’é™¤
]
branch = true  # åˆ†æ”¯è¦†ç›–ç‡

[tool.coverage.report]
exclude_lines = [
    "pragma: no cover",
    "def __repr__",
    "raise AssertionError",
    "raise NotImplementedError",
    "if __name__ == .__main__.:",
    "if TYPE_CHECKING:",
]
fail_under = 100  # å¿…é¡»100%è¦†ç›–

[tool.black]
line-length = 100
target-version = ['py311']

[tool.isort]
profile = "black"
line_length = 100

[tool.mypy]
python_version = "3.11"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true
disallow_incomplete_defs = true
check_untyped_defs = true
no_implicit_optional = true
warn_redundant_casts = true
warn_unused_ignores = true
show_error_codes = true

[tool.pylint.messages_control]
disable = [
    "C0103",  # å¸¸é‡å‘½åï¼ˆæˆ‘ä»¬ä½¿ç”¨UPPER_SNAKE_CASEï¼‰
    "R0903",  # ç±»æ–¹æ³•å¤ªå°‘ï¼ˆæ•°æ®ç±»å…è®¸ï¼‰
]

[tool.pylint.format]
max-line-length = 100

[tool.pylint.design]
max-args = 8
max-attributes = 15
max-branches = 15
max-statements = 50
max-parents = 7
max-complexity = 10  # åœˆå¤æ‚åº¦é™åˆ¶
```

**ä»£ç è´¨é‡æ£€æŸ¥è„šæœ¬**: `scripts/quality_check.sh`

```bash
#!/bin/bash
set -e

echo "=== ä»£ç è´¨é‡æ£€æŸ¥ ==="

echo "1. ä»£ç æ ¼å¼åŒ–æ£€æŸ¥ (Black)..."
black --check backend/

echo "2. å¯¼å…¥æ’åºæ£€æŸ¥ (isort)..."
isort --check-only backend/

echo "3. ç±»å‹æ£€æŸ¥ (mypy)..."
mypy backend/

echo "4. ä»£ç é£æ ¼æ£€æŸ¥ (pylint)..."
pylint backend/ --rcfile=pyproject.toml

echo "5. åœˆå¤æ‚åº¦æ£€æŸ¥ (xenon)..."
xenon backend/ --max-absolute B --max-modules A --max-average A

echo "6. å®‰å…¨æ¼æ´æ£€æŸ¥ (bandit)..."
bandit -r backend/ -f json -o reports/security.json || true

echo "7. æµ‹è¯•è¦†ç›–ç‡æ£€æŸ¥..."
pytest test/backend/ --cov=backend --cov-fail-under=100

echo "=== æ‰€æœ‰æ£€æŸ¥é€šè¿‡ ==="
```

**åœˆå¤æ‚åº¦ç›‘æ§**:

```python
# åœ¨CIä¸­é›†æˆ
# .github/workflows/quality.yml

name: Code Quality
on: [push, pull_request]

jobs:
  quality:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install black isort mypy pylint xenon bandit pytest pytest-cov
      
      - name: Run quality checks
        run: |
          black --check backend/
          isort --check-only backend/
          mypy backend/
          pylint backend/ --fail-under=9.0  # pylintè¯„åˆ†å¿…é¡»>=9.0
          xenon backend/ --max-absolute B --max-modules A --max-average A
      
      - name: Run tests with coverage
        run: |
          pytest test/backend/ --cov=backend --cov-fail-under=100 --cov-report=xml
      
      - name: Upload coverage
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
          fail_ci_if_error: true
```

### 10.7 æµ‹è¯•æ•°æ®ç®¡ç†

**æ–‡ä»¶**: `test/backend/data/`

```
test/backend/data/
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ valid/
â”‚   â”‚   â”œâ”€â”€ minimal.yml          # æœ€å°é…ç½®
â”‚   â”‚   â”œâ”€â”€ full.yml             # å®Œæ•´é…ç½®
â”‚   â”‚   â””â”€â”€ chinese_characters.yml  # ä¸­æ–‡é…ç½®
â”‚   â””â”€â”€ invalid/
â”‚       â”œâ”€â”€ empty.yml            # ç©ºæ–‡ä»¶
â”‚       â”œâ”€â”€ syntax_error.yml     # YAMLè¯­æ³•é”™è¯¯
â”‚       â”œâ”€â”€ missing_required.yml # ç¼ºå°‘å¿…å¡«å­—æ®µ
â”‚       â””â”€â”€ invalid_value.yml    # æ— æ•ˆå€¼
â”œâ”€â”€ documents/
â”‚   â”œâ”€â”€ sample.pdf               # æµ‹è¯•PDF
â”‚   â”œâ”€â”€ sample.txt               # æµ‹è¯•æ–‡æœ¬
â”‚   â”œâ”€â”€ sample_with_bom.txt      # å¸¦BOMçš„æ–‡æœ¬ï¼ˆè¾¹ç•Œæµ‹è¯•ï¼‰
â”‚   â””â”€â”€ large_file_10mb.txt      # å¤§æ–‡ä»¶ï¼ˆè¾¹ç•Œæµ‹è¯•ï¼‰
â”œâ”€â”€ audio/
â”‚   â”œâ”€â”€ sample_5s.mp3            # 5ç§’éŸ³é¢‘
â”‚   â”œâ”€â”€ sample_5min.mp3          # 5åˆ†é’ŸéŸ³é¢‘
â”‚   â””â”€â”€ sample_chinese.mp3       # ä¸­æ–‡éŸ³é¢‘
â””â”€â”€ skills/
    â”œâ”€â”€ valid/
    â”‚   â”œâ”€â”€ router_rule_based.md
    â”‚   â””â”€â”€ router_llm_based.md
    â””â”€â”€ invalid/
        â”œâ”€â”€ missing_frontmatter.md
        â”œâ”€â”€ invalid_yaml.md
        â””â”€â”€ missing_required_field.md
```

### 10.8 æµ‹è¯•æ‰§è¡Œå‘½ä»¤

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest test/backend/

# è¿è¡Œç‰¹å®šæ¨¡å—æµ‹è¯•
pytest test/backend/core/test_skill_manager.py

# è¿è¡Œç‰¹å®šä¼˜å…ˆçº§æµ‹è¯•
pytest test/backend/ -m "P0"

# è¿è¡Œè¾¹ç•Œæµ‹è¯•
pytest test/backend/ -m "boundary"

# ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
pytest test/backend/ --html=reports/report.html --self-contained-html

# æ£€æŸ¥è¦†ç›–ç‡ï¼ˆå¿…é¡»100%ï¼‰
pytest test/backend/ --cov=backend --cov-fail-under=100

# ç”Ÿæˆè¦†ç›–ç‡HTMLæŠ¥å‘Š
pytest test/backend/ --cov=backend --cov-report=html:reports/coverage

# ä»£ç è´¨é‡æ£€æŸ¥
black backend/
isort backend/
mypy backend/
pylint backend/
```

### 10.9 æµ‹è¯•æ¡ˆä¾‹æ¸…å•ï¼ˆéƒ¨åˆ†ç¤ºä¾‹ï¼‰

**å¿…é¡»ç¼–å†™çš„æµ‹è¯•æ¡ˆä¾‹æ•°é‡**: 
- å•å…ƒæµ‹è¯•: æ¯ä¸ªå‡½æ•°è‡³å°‘3ä¸ªæ¡ˆä¾‹ï¼ˆæ­£å¸¸ã€è¾¹ç•Œã€å¼‚å¸¸ï¼‰
- é›†æˆæµ‹è¯•: æ¯ä¸ªAPIç«¯ç‚¹è‡³å°‘5ä¸ªæ¡ˆä¾‹
- è¾¹ç•Œæµ‹è¯•: æ¯ä¸ªæ¨¡å—è‡³å°‘10ä¸ªæ¡ˆä¾‹
- æ€§èƒ½æµ‹è¯•: å…³é”®è·¯å¾„è‡³å°‘3ä¸ªæ¡ˆä¾‹

**é¢„è®¡æ€»æµ‹è¯•æ¡ˆä¾‹æ•°**: 500-800ä¸ª

**æµ‹è¯•æ¡ˆä¾‹ç¼–å†™è§„èŒƒ**:
1. **å‘½åè§„èŒƒ**: `test_{è¢«æµ‹å¯¹è±¡}_{åœºæ™¯}_{é¢„æœŸç»“æœ}`
2. **æ³¨é‡Šè§„èŒƒ**: å¿…é¡»åŒ…å«æµ‹è¯•ç›®çš„ã€å‰ç½®æ¡ä»¶ã€æµ‹è¯•æ­¥éª¤
3. **æ–­è¨€è§„èŒƒ**: æ¯ä¸ªæµ‹è¯•è‡³å°‘3ä¸ªæ–­è¨€
4. **æ•°æ®è§„èŒƒ**: æµ‹è¯•æ•°æ®ä¸ä»£ç åˆ†ç¦»ï¼Œä½¿ç”¨JSONæˆ–fixture

---

## 11. å¯æ‰©å±•è·¯ç”±æ¶æ„è®¾è®¡

### 11.1 è®¾è®¡ç†å¿µ

å½“å‰ç‰ˆæœ¬æ”¯æŒ **small/big** ä¸¤ä¸ªæ¨¡å‹ï¼Œä½†æ¶æ„å¿…é¡»æ”¯æŒæœªæ¥æ‰©å±•åˆ° **N ä¸ªæ¨¡å‹**ï¼ˆmodel_1, model_2, ... model_nï¼‰ã€‚

**è®¾è®¡åŸåˆ™**:
1. **å‘åå…¼å®¹**: ç°æœ‰ small/big é…ç½®ç»§ç»­å·¥ä½œ
2. **æ¸è¿›æ‰©å±•**: æœªæ¥å¯æ·»åŠ ä»»æ„æ•°é‡çš„æ¨¡å‹
3. **é…ç½®é©±åŠ¨**: é€šè¿‡ YAML é…ç½®åŠ¨æ€å®šä¹‰æ¨¡å‹
4. **ç»Ÿä¸€æŠ½è±¡**: æ‰€æœ‰æ¨¡å‹ä½¿ç”¨ç›¸åŒçš„é…ç½®ç»“æ„

### 11.2 é…ç½®ç»“æ„ï¼ˆå¯æ‰©å±•ç‰ˆï¼‰

```yaml
ai-gateway:
  virtual_models:
    demo1:
      proxy_key: "xxx"
      base_url: "http://..."
      
      # ========== è·¯ç”±é…ç½®ï¼ˆæ ¸å¿ƒï¼‰==========
      routing:
        current: "small"              # å½“å‰é»˜è®¤æ¨¡å‹ID
        force_current: false          # æ˜¯å¦å¼ºåˆ¶ä½¿ç”¨current
        
        # å…³é”®è¯åˆ‡æ¢é…ç½®
        keyword_switching:
          enabled: true
          rules:                      # å…³é”®è¯è§„åˆ™åˆ—è¡¨ï¼ˆå¯æ‰©å±•ï¼‰
            - pattern: "@å¤§å“¥"
              target: "big"          # ç›®æ ‡æ¨¡å‹ID
            - pattern: "@å°å¼Ÿ" 
              target: "small"
            - pattern: "@code"
              target: "coding"       # æœªæ¥å¯æ‰©å±•åˆ°å…¶ä»–æ¨¡å‹
        
        # æ¨¡å‹åˆ—è¡¨ï¼ˆå¯æ‰©å±•ï¼Œå½“å‰2ä¸ªï¼Œæœªæ¥Nä¸ªï¼‰
        models:
          small:                      # æ¨¡å‹ID
            name: "deepseek-ai/DeepSeek-R1-0528-Qwen3-8B"
            api_key: "sk-xxx"
            base_url: "https://api.siliconflow.cn/v1"
            provider: "siliconflow"
            priority: 1               # ä¼˜å…ˆçº§ï¼ˆç”¨äºæ’åºæ˜¾ç¤ºï¼‰
          big:
            name: "Pro/deepseek-ai/DeepSeek-V3.2"
            api_key: "sk-xxx"
            base_url: "https://api.siliconflow.cn/v1"
            provider: "siliconflow"
            priority: 2
          # coding:                  # æœªæ¥å¯æ·»åŠ ç¬¬3ã€4ã€Nä¸ªæ¨¡å‹
          #   name: "codellama/CodeLlama-70b-Instruct-hf"
          #   api_key: "sk-xxx"
          #   base_url: "https://api.siliconflow.cn/v1"
          #   provider: "siliconflow"
          #   priority: 3
      
      # å…¶ä»–é…ç½®ä¿æŒä¸å˜
      knowledge:
        enabled: true
      web_search:
        enabled: true
```

### 11.3 å…³é”®è®¾è®¡ç‚¹

#### 1. ä½¿ç”¨ `models` å¯¹è±¡æ›¿ä»£å›ºå®šçš„ `small/big`

**å½“å‰ç‰ˆæœ¬ï¼ˆ2ä¸ªæ¨¡å‹ï¼‰**:
```yaml
small: { ... }
big: { ... }
```

**æœªæ¥ç‰ˆæœ¬ï¼ˆNä¸ªæ¨¡å‹ï¼‰**:
```yaml
models:
  small: { ... }
  big: { ... }
  coding: { ... }
  vision: { ... }
  # ... ä»»æ„æ•°é‡
```

#### 2. è·¯ç”±ç›®æ ‡ä½¿ç”¨æ¨¡å‹IDï¼ˆå­—ç¬¦ä¸²ï¼‰è€Œéæšä¸¾

```python
# å½“å‰
model_type: Literal["small", "big"]

# æœªæ¥ï¼ˆå¯æ‰©å±•ï¼‰
target_model: str  # å¯ä»¥æ˜¯ "small", "big", "coding", "vision" ç­‰ä»»æ„ID
```

### 11.4 Pydantic æ¨¡å‹è®¾è®¡

```python
# å¯æ‰©å±•æ¨¡å‹é…ç½®
class ModelConfig(BaseModel):
    """å•ä¸ªæ¨¡å‹é…ç½®ï¼ˆå¯æ‰©å±•ï¼‰"""
    name: str                    # æ¨¡å‹åç§°ï¼ˆå¦‚ deepseek-ai/DeepSeek-V3ï¼‰
    api_key: Optional[str] = None
    base_url: Optional[str] = None
    provider: str = "siliconflow"  # æä¾›å•†
    priority: int = 1            # æ˜¾ç¤ºä¼˜å…ˆçº§

class KeywordRule(BaseModel):
    """å…³é”®è¯è§„åˆ™"""
    pattern: str                 # åŒ¹é…æ¨¡å¼
    target: str                  # ç›®æ ‡æ¨¡å‹IDï¼ˆä»»æ„å­—ç¬¦ä¸²ï¼Œä¸é™äºsmall/bigï¼‰

class KeywordSwitchingConfig(BaseModel):
    """å…³é”®è¯åˆ‡æ¢é…ç½®"""
    enabled: bool = False
    rules: List[KeywordRule] = Field(default_factory=list)

class RoutingConfig(BaseModel):
    """è·¯ç”±é…ç½®ï¼ˆæ ¸å¿ƒå¯æ‰©å±•éƒ¨åˆ†ï¼‰"""
    current: str = "small"       # å½“å‰é»˜è®¤æ¨¡å‹IDï¼ˆä»»æ„å­—ç¬¦ä¸²ï¼‰
    force_current: bool = False  # æ˜¯å¦å¼ºåˆ¶
    models: Dict[str, ModelConfig] = Field(default_factory=dict)  # åŠ¨æ€æ¨¡å‹åˆ—è¡¨
    keyword_switching: KeywordSwitchingConfig = Field(default_factory=KeywordSwitchingConfig)

class VirtualModel(BaseModel):
    """è™šæ‹Ÿæ¨¡å‹ï¼ˆåŒ…å«å¯æ‰©å±•çš„è·¯ç”±é…ç½®ï¼‰"""
    name: str
    proxy_key: str
    base_url: Optional[str] = None
    use: bool = True
    
    # æ–°çš„å¯æ‰©å±•è·¯ç”±é…ç½®
    routing: RoutingConfig = Field(default_factory=RoutingConfig)
    
    # å‘åå…¼å®¹ï¼šä¿ç•™æ—§çš„ small/big é…ç½®
    # è¿ç§»æ—¶è‡ªåŠ¨è½¬æ¢åˆ° routing.models
    
    # å…¶ä»–é…ç½®
    knowledge: KnowledgeConfig = Field(default_factory=KnowledgeConfig)
    web_search: WebSearchConfig = Field(default_factory=WebSearchConfig)
```

### 11.5 è·¯ç”±å¼•æ“ï¼ˆæ”¯æŒåŠ¨æ€æ¨¡å‹ï¼‰

```python
# model_router.py
class ModelRouter:
    async def route(
        self, 
        virtual_model: str, 
        user_input: str,
        conversation_id: Optional[str] = None
    ) -> RouteResult:
        """
        æ¨¡å‹è·¯ç”±å†³ç­–ï¼ˆæ”¯æŒåŠ¨æ€æ¨¡å‹ï¼‰
        """
        vm_config = self._config_manager.get(f"ai-gateway.virtual_models.{virtual_model}")
        if not vm_config:
            return RouteResult(model_type="small", reason="é…ç½®ä¸å­˜åœ¨")
        
        routing = vm_config.get("routing", {})
        
        # 1. æ£€æŸ¥å¼ºåˆ¶æ¨¡å¼
        if routing.get("force_current", False):
            current = routing.get("current", "small")
            return RouteResult(
                model_type=current,
                reason="å¼ºåˆ¶æ¨¡å¼",
                confidence=1.0
            )
        
        # 2. æ£€æŸ¥å…³é”®è¯åˆ‡æ¢
        keyword_config = routing.get("keyword_switching", {})
        if keyword_config.get("enabled", False):
            user_input_lower = user_input.lower()
            
            for rule in keyword_config.get("rules", []):
                pattern = rule.get("pattern", "")
                target = rule.get("target", "")
                
                if pattern.lower() in user_input_lower:
                    # éªŒè¯ç›®æ ‡æ¨¡å‹æ˜¯å¦å­˜åœ¨
                    available_models = routing.get("models", {})
                    if target in available_models:
                        return RouteResult(
                            model_type=target,  # è¿”å›åŠ¨æ€æ¨¡å‹ID
                            matched_rule=f"keyword:{pattern}",
                            reason=f"å…³é”®è¯åŒ¹é…: {pattern}",
                            confidence=1.0
                        )
        
        # 3. ä½¿ç”¨é»˜è®¤æ¨¡å‹
        current = routing.get("current", "small")
        return RouteResult(
            model_type=current,
            reason="ä½¿ç”¨é»˜è®¤æ¨¡å‹"
        )
```

### 11.6 è¿ç§»ç­–ç•¥ï¼ˆå‘åå…¼å®¹ï¼‰

#### æ–¹æ¡ˆ Aï¼šè‡ªåŠ¨è¿ç§»ï¼ˆæ¨èï¼‰

åœ¨è¯»å–é…ç½®æ—¶è‡ªåŠ¨å°†æ—§æ ¼å¼è½¬æ¢ä¸ºæ–°æ ¼å¼ï¼š

```python
def migrate_virtual_model_config(config: dict) -> dict:
    """è‡ªåŠ¨è¿ç§»æ—§é…ç½®åˆ°æ–°æ ¼å¼"""
    if "routing" in config:
        return config  # å·²ç»æ˜¯æ–°æ ¼å¼
    
    # æ—§æ ¼å¼è½¬æ¢
    routing = {
        "current": config.get("current", "small"),
        "force_current": config.get("force-current", False),
        "models": {
            "small": config.get("small", {}),
            "big": config.get("big", {})
        },
        "keyword_switching": config.get("keyword_switching", {
            "enabled": False,
            "rules": []
        })
    }
    
    config["routing"] = routing
    return config
```

#### æ–¹æ¡ˆ Bï¼šåŒè½¨æ”¯æŒ

åŒæ—¶æ”¯æŒæ–°æ—§ä¸¤ç§é…ç½®æ ¼å¼ï¼š

```python
# è¯»å–æ—¶ä¼˜å…ˆä½¿ç”¨æ–°æ ¼å¼ï¼Œ fallback åˆ°æ—§æ ¼å¼
models = routing.get("models", {
    "small": config.get("small"),
    "big": config.get("big")
})
```

### 11.7 å®æ–½é˜¶æ®µ

**é˜¶æ®µ 1**ï¼ˆå½“å‰ç‰ˆæœ¬ï¼‰ï¼š
1. å®ç°æ–°çš„ `routing` é…ç½®ç»“æ„
2. ä¿æŒåªæ”¯æŒ small/big ä¸¤ä¸ªæ¨¡å‹
3. ç¡®ä¿ä»£ç æ¶æ„æ”¯æŒæœªæ¥æ‰©å±•
4. æ·»åŠ è‡ªåŠ¨è¿ç§»é€»è¾‘

**é˜¶æ®µ 2**ï¼ˆæœªæ¥ç‰ˆæœ¬ï¼‰ï¼š
1. æ·»åŠ  "+ æ·»åŠ æ¨¡å‹" åŠŸèƒ½
2. æ”¯æŒä»»æ„æ•°é‡çš„æ¨¡å‹
3. æ·»åŠ æ¨¡å‹ä¼˜å…ˆçº§æ’åº
4. æ›´æ–°å‰ç«¯UIæ”¯æŒåŠ¨æ€æ¨¡å‹

---

## 12. å¼€å‘é¡ºåº

æŒ‰ç…§ä»¥ä¸‹é¡ºåºå®ç°åç«¯æ¨¡å—:

```
Phase 1: åŸºç¡€è®¾æ–½
  1.1 é¡¹ç›®ç»“æ„æ­å»º
  1.2 æ•°æ®åº“è¿æ¥ (MongoDB/Redis/Qdrant)
  1.3 é…ç½®ç®¡ç†å™¨
  1.4 æ—¥å¿—ç³»ç»Ÿ

Phase 2: æ ¸å¿ƒåŠŸèƒ½
  2.1 APIè·¯ç”±æ¡†æ¶
  2.2 ä»£ç†è®¤è¯ä¸­é—´ä»¶
  2.3 è™šæ‹Ÿæ¨¡å‹ç®¡ç†API
  2.4 å¯¹è¯æ¥å£ (/proxy/ai/v1/chat)
  2.5 å¯¹è¯å†å²ç®¡ç†

Phase 3: Skillç³»ç»Ÿ
  3.1 Skillç®¡ç†å™¨
  3.2 SkilléªŒè¯å™¨
  3.3 Skillæ‰§è¡Œå™¨
  3.4 æ¨¡å‹è·¯ç”±å¼•æ“
  3.5 Skillç®¡ç†API

Phase 4: çŸ¥è¯†åº“
  4.1 EmbeddingæœåŠ¡
  4.2 æ–‡æ¡£ä¸Šä¼ /åˆ†æ®µ
  4.3 å‘é‡å­˜å‚¨/æ£€ç´¢
  4.4 çŸ¥è¯†æå–Skill
  4.5 çŸ¥è¯†åº“ç®¡ç†API

Phase 5: åª’ä½“å¤„ç†
  5.1 WhisperæœåŠ¡é›†æˆ
  5.2 æ–‡ä»¶ä¸Šä¼ /ä¸‹è½½
  5.3 è½¬å½•ä»»åŠ¡é˜Ÿåˆ—
  5.4 åª’ä½“å¤„ç†API

Phase 6: RSS
  6.1 RSSè§£æå™¨
  6.2 å†…å®¹æå– (readability)
  6.3 å®šæ—¶æŠ“å–ä»»åŠ¡
  6.4 RSSç®¡ç†API

Phase 7: å…¶ä»–
  7.1 çœ‹æ¿ç»Ÿè®¡API
  7.2 æ—¥å¿—æŸ¥è¯¢API
  7.3 åŸå§‹æ•°æ®API
  7.4 ç³»ç»Ÿé…ç½®API
```

---

## 12. ä¾èµ–æ¸…å•

**requirements.txt**:
```
# Webæ¡†æ¶
fastapi==0.109.0
uvicorn[standard]==0.27.0

# æ•°æ®éªŒè¯
pydantic==2.5.0
pydantic-settings==2.1.0

# æ•°æ®åº“
motor==3.3.0              # MongoDBå¼‚æ­¥é©±åŠ¨
redis==5.0.0              # Rediså®¢æˆ·ç«¯
qdrant-client==1.7.0      # Qdrantå®¢æˆ·ç«¯

# HTTPå®¢æˆ·ç«¯
httpx==0.26.0

# YAMLå¤„ç†
pyyaml==6.0.1

# æ–‡ä»¶ç›‘æ§ï¼ˆçƒ­é‡è½½ï¼‰
watchdog==3.0.0

# RSSè§£æ
feedparser==6.0.10

# HTMLå†…å®¹æå–
readability-lxml==0.8.1
html2text==2020.1.16

# æ—¥å¿—
python-json-logger==2.0.7

# å·¥å…·
python-multipart==0.0.6   # æ–‡ä»¶ä¸Šä¼ 
python-jose[cryptography]==3.3.0  # JWTï¼ˆé¢„ç•™ï¼‰

# æµ‹è¯•
pytest==7.4.0
pytest-asyncio==0.21.0
pytest-cov==4.1.0
httpx==0.26.0
```

ZS|---
XK|
JN|## 12. RSSæ¨¡å—è®¾è®¡ (RSS Fetcher)
TK|
TV|**æ–‡ä»¶ä½ç½®**: `backend/core/rss_fetcher.py`
QT|
MZ|**èŒè´£**: RSSè®¢é˜…ç®¡ç†ã€æ–‡ç« æŠ“å–ã€å†…å®¹æå–ã€æ–‡ç« ç®¡ç†
MZ|
HB|### 12.1 æ•°æ®æ¨¡å‹
RT|
HM|```python
@dataclass
class RSSSubscription:
    """RSSè®¢é˜…æº"""
    id: str
    name: str
    url: str
    enabled: bool = True
    update_interval: int = 30  # åˆ†é’Ÿ
    retention_days: int = 30
    default_permanent: bool = False
    article_count: int = 0
    last_fetch_time: Optional[datetime] = None
    created_at: Optional[datetime] = None
    updated_at: Optional[datetime] = None

@dataclass
class RSSArticle:
    """RSSæ–‡ç« """
    id: str
    subscription_id: str
    title: str
    url: str
    content: str
    raw_content: str
    content_format: str = "markdown"
    published_at: Optional[datetime] = None
    fetched_at: Optional[datetime] = None
    is_read: bool = False
    knowledge_extracted: bool = False
    knowledge_doc_ids: List[str] = field(default_factory=list)
    fetch_status: str = "summary"  # full_content/rss_summary/blocked/failed
    fetch_method: str = "rss_only"
```

XS|
HB|### 12.2 RSSFetcherç±»è®¾è®¡
RT|
HM|```python
class RSSFetcher:
    """RSSæŠ“å–å™¨ - ç®¡ç†è®¢é˜…å’Œæ–‡ç« """
    
    def __init__(self, db, config_manager):
        self._db = db
        self._config = config_manager
    
    # === è®¢é˜…æºç®¡ç† ===
    
    async def create_subscription(self, data: Dict) -> str:
        """åˆ›å»ºè®¢é˜…æº"""
        
    async def list_subscriptions(self, enabled_only: bool = False) -> List[RSSSubscription]:
        """åˆ—å‡ºæ‰€æœ‰è®¢é˜…æº"""
        
    async def get_subscription(self, feed_id: str) -> Optional[RSSSubscription]:
        """è·å–è®¢é˜…æºè¯¦æƒ…"""
        
    async def update_subscription(self, feed_id: str, data: Dict) -> bool:
        """æ›´æ–°è®¢é˜…æº"""
        
    async def delete_subscription(self, feed_id: str) -> bool:
        """åˆ é™¤è®¢é˜…æºï¼ˆçº§è”åˆ é™¤æ‰€æœ‰æ–‡ç« ï¼‰"""
        
    async def fetch_feed(self, feed_id: str) -> Dict:
        """ç«‹å³æŠ“å–è®¢é˜…æºå†…å®¹"""
    
    # === æ–‡ç« ç®¡ç† ===
    
    async def list_articles(
        self, 
        feed_id: Optional[str] = None, 
        is_read: Optional[bool] = None,
        page: int = 1,
        page_size: int = 20
    ) -> Tuple[List[RSSArticle], int]:
        """åˆ—å‡ºæ–‡ç« ï¼Œæ”¯æŒç­›é€‰å’Œåˆ†é¡µ"""
        
    async def get_article(self, article_id: str) -> Optional[RSSArticle]:
        """è·å–å•ç¯‡æ–‡ç« è¯¦æƒ…"""
        
    async def mark_article_read(self, article_id: str, is_read: bool = True) -> bool:
        """æ ‡è®°æ–‡ç« å·²è¯»/æœªè¯»çŠ¶æ€"""
        
    async def delete_article(self, article_id: str) -> bool:
        """
        åˆ é™¤å•ç¯‡æ–‡ç« 
        
        Args:
            article_id: æ–‡ç« ID
            
        Returns:
            bool: æ˜¯å¦åˆ é™¤æˆåŠŸ
            
        åˆ é™¤æ“ä½œï¼š
        1. ä» MongoDB åˆ é™¤æ–‡ç« è®°å½•
        2. å¦‚æœæ–‡ç« æœ‰å…³è”çš„çŸ¥è¯†åº“æ–‡æ¡£ï¼Œä¿ç•™ï¼ˆç”±çŸ¥è¯†åº“ç®¡ç†ï¼‰
        3. æ›´æ–°è®¢é˜…æºçš„æ–‡ç« è®¡æ•°
        """
        
    async def delete_articles(self, article_ids: List[str]) -> Dict[str, Any]:
        """
        æ‰¹é‡åˆ é™¤æ–‡ç« 
        
        Args:
            article_ids: æ–‡ç« IDåˆ—è¡¨
            
        Returns:
            Dict: {
                "success_count": æˆåŠŸåˆ é™¤æ•°é‡,
                "failed_count": å¤±è´¥æ•°é‡,
                "failed_ids": å¤±è´¥çš„æ–‡ç« IDåˆ—è¡¨
            }
            
        è¯´æ˜ï¼š
        - å³ä½¿éƒ¨åˆ†åˆ é™¤å¤±è´¥ï¼Œä¹Ÿä¼šç»§ç»­å¤„ç†å…¶ä»–ID
        - è¿”å›è¯¦ç»†çš„åˆ é™¤ç»“æœ
        """
    
    # === å†…å®¹æŠ“å– ===
    
    async def _fetch_full_content(self, url: str) -> Tuple[str, str]:
        """æŠ“å–æ–‡ç« å®Œæ•´å†…å®¹"""
        
    async def _extract_with_readability(self, html: str) -> str:
        """ä½¿ç”¨readabilityæå–æ­£æ–‡"""
```

XS|
HB|### 12.3 APIç«¯ç‚¹è®¾è®¡
RT|
HB|**è®¢é˜…æºç«¯ç‚¹**:
HM|| ç«¯ç‚¹ | æ–¹æ³• | åŠŸèƒ½ |
QT||------|------|------|
MZ|| `/admin/ai/v1/rss/feeds` | GET | è·å–è®¢é˜…æºåˆ—è¡¨ |
MZ|| `/admin/ai/v1/rss/feeds` | POST | åˆ›å»ºè®¢é˜…æº |
MZ|| `/admin/ai/v1/rss/feeds/{id}` | PUT | æ›´æ–°è®¢é˜…æº |
MZ|| `/admin/ai/v1/rss/feeds/{id}` | DELETE | åˆ é™¤è®¢é˜…æº |
MZ|| `/admin/ai/v1/rss/feeds/{id}/fetch` | POST | ç«‹å³æŠ“å– |

XS|
HB|**æ–‡ç« ç«¯ç‚¹**:
HM|| ç«¯ç‚¹ | æ–¹æ³• | åŠŸèƒ½ |
QT||------|------|------|
MZ|| `/admin/ai/v1/rss/articles` | GET | è·å–æ–‡ç« åˆ—è¡¨ |
MZ|| `/admin/ai/v1/rss/articles/{id}` | GET | è·å–æ–‡ç« è¯¦æƒ… |
MZ|| `/admin/ai/v1/rss/articles/{id}/read` | POST | æ ‡è®°å·²è¯»/æœªè¯» |
MZ|| `/admin/ai/v1/rss/articles/{id}` | DELETE | **åˆ é™¤å•ç¯‡æ–‡ç« ** |
MZ|| `/admin/ai/v1/rss/articles/batch` | DELETE | **æ‰¹é‡åˆ é™¤æ–‡ç« ** |

XS|
HB|### 12.4 åˆ é™¤æ–‡ç« å®ç°ç»†èŠ‚
RT|
HB|**å•ç¯‡åˆ é™¤æµç¨‹**:
HM|```
1. éªŒè¯æ–‡ç« IDæ˜¯å¦å­˜åœ¨
2. ä» MongoDB rss_articles é›†åˆåˆ é™¤æ–‡æ¡£
3. æ›´æ–°å¯¹åº”è®¢é˜…æºçš„ article_countï¼ˆå‡1ï¼‰
4. è¿”å›åˆ é™¤ç»“æœ
```

XS|
HB|**æ‰¹é‡åˆ é™¤æµç¨‹**:
HM|```
1. éå†æ–‡ç« IDåˆ—è¡¨
2. å¯¹æ¯ä¸ªIDæ‰§è¡Œåˆ é™¤æ“ä½œ
3. è®°å½•æˆåŠŸå’Œå¤±è´¥çš„ID
4. æ‰¹é‡æ›´æ–°è®¢é˜…æºæ–‡ç« è®¡æ•°
5. è¿”å›ç»Ÿè®¡ç»“æœï¼šæˆåŠŸæ•°ã€å¤±è´¥æ•°ã€å¤±è´¥IDåˆ—è¡¨
```

XS|
HB|### 12.5 é”™è¯¯å¤„ç†
RT|
HB|| é”™è¯¯åœºæ™¯ | HTTPçŠ¶æ€ç  | é”™è¯¯ä¿¡æ¯ |
QT||----------|------------|----------|
MZ|| æ–‡ç« ä¸å­˜åœ¨ | 404 | "æ–‡ç« ä¸å­˜åœ¨" |
MZ|| åˆ é™¤å¤±è´¥ | 500 | "åˆ é™¤æ“ä½œå¤±è´¥: {detail}" |
MZ|| éƒ¨åˆ†æ‰¹é‡åˆ é™¤å¤±è´¥ | 200 | è¿”å›å¤±è´¥åˆ—è¡¨ |

XS|
XP|**æ–‡æ¡£ç‰ˆæœ¬**: 1.1

**æ–‡æ¡£ç‰ˆæœ¬**: 1.1  
**çŠ¶æ€**: å·²æ›´æ–°  
**å®¡æ ¸äºº**: ç”¨æˆ·ç¡®è®¤åå®æ–½å¼€å‘

---

## æ–‡æ¡£æ›´æ–°è®°å½•

| ç‰ˆæœ¬ | æ—¥æœŸ | æ›´æ–°å†…å®¹ | ä½œè€… |
|------|------|----------|------|
| 1.1 | 2026-02-14 | æ–°å¢ç¬¬11ç« ï¼šå¯æ‰©å±•è·¯ç”±æ¶æ„è®¾è®¡ | AI Assistant |
| 1.0 | 2026-02-24 | åˆå§‹ç‰ˆæœ¬ | å¼€å‘å›¢é˜Ÿ |
